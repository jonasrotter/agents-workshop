{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c3165f6",
   "metadata": {},
   "source": [
    "# Scenario 04: Deterministic Multi-Agent Workflows\n",
    "\n",
    "**Estimated Time**: 45 minutes\n",
    "\n",
    "## Learning Objectives\n",
    "- Design deterministic workflows using Microsoft Agent Framework's `WorkflowBuilder`\n",
    "- Implement sequential agent chains with `add_edge()`\n",
    "- Execute parallel agent operations with `asyncio.gather()`\n",
    "- Handle conditional routing with condition functions\n",
    "- Use middleware patterns for error handling and retry logic\n",
    "\n",
    "## Prerequisites\n",
    "- Completed Scenario 01 (Simple Agent + MCP)\n",
    "- Understanding of async/await patterns in Python\n",
    "- Azure OpenAI access configured in `.env`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3eba18",
   "metadata": {},
   "source": [
    "## Part 1: Understanding Deterministic Workflows\n",
    "\n",
    "### What Are Deterministic Workflows?\n",
    "\n",
    "Deterministic workflows define a **fixed execution path** for coordinating multiple agents:\n",
    "\n",
    "- **Predictable**: Same inputs produce same execution order\n",
    "- **Debuggable**: Clear step-by-step execution trace\n",
    "- **Testable**: Each step can be tested independently\n",
    "- **Recoverable**: Built-in error handling and retry logic\n",
    "\n",
    "### When to Use Deterministic Workflows\n",
    "\n",
    "- ETL pipelines with agent transformations\n",
    "- Document processing (extract â†’ analyze â†’ summarize)\n",
    "- Research workflows (search â†’ analyze â†’ report)\n",
    "- Approval workflows with human-in-the-loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9501b82a",
   "metadata": {},
   "source": [
    "## Part 2: Setting Up the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50230242-2614-417f-8abc-bb7b1bf407f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Removed AZURE_OPENAI_API_KEY from environment to force Entra ID auth\n",
      "âœ… Project root: C:\\Users\\jonasrotter\\OneDrive - Microsoft\\Desktop\\Jonas Privat\\MyCodingProjects\\agents-workshop\n",
      "âœ… Azure OpenAI endpoint: https://aistudiojonasr5312406741.openai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "# Load environment and configure paths\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path(\"..\").resolve()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Load environment variables (force override cached values)\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(project_root / \".env\", override=True)\n",
    "\n",
    "# IMPORTANT: Remove API key from env to force Entra ID auth\n",
    "if \"AZURE_OPENAI_API_KEY\" in os.environ:\n",
    "    del os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "    print(\"âš ï¸ Removed AZURE_OPENAI_API_KEY from environment to force Entra ID auth\")\n",
    "\n",
    "# Verify Azure OpenAI configuration\n",
    "assert os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \"Missing AZURE_OPENAI_ENDPOINT\"\n",
    "assert os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"), \"Missing AZURE_OPENAI_DEPLOYMENT\"\n",
    "\n",
    "print(f\"âœ… Project root: {project_root}\")\n",
    "print(f\"âœ… Azure OpenAI endpoint: {os.getenv('AZURE_OPENAI_ENDPOINT')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecf3e9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Microsoft Agent Framework components imported!\n",
      "âœ… Azure OpenAI client created with deployment: gpt-4.1-mini\n",
      "âœ… Helper function 'extract_response_text()' defined for use in all cells\n"
     ]
    }
   ],
   "source": [
    "# Import Microsoft Agent Framework components\n",
    "import os\n",
    "import asyncio\n",
    "from typing import Any, Callable\n",
    "\n",
    "# Agent Framework imports\n",
    "from agent_framework import WorkflowBuilder, ChatAgent\n",
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "# Telemetry setup\n",
    "from src.common.telemetry import setup_telemetry, get_tracer\n",
    "setup_telemetry()\n",
    "tracer = get_tracer(__name__)\n",
    "\n",
    "# =============================================================================\n",
    "# Helper Function: Extract text from AgentRunResponse\n",
    "# =============================================================================\n",
    "# This helper is used throughout the notebook to extract text from agent responses.\n",
    "# Defined once here and reused in all cells.\n",
    "\n",
    "def extract_response_text(response) -> str:\n",
    "    \"\"\"Extract text content from AgentRunResponse or return string as-is.\n",
    "    \n",
    "    Handles multiple response formats from Microsoft Agent Framework:\n",
    "    - String responses (returned directly)\n",
    "    - AgentRunResponse with .text attribute\n",
    "    - AgentRunResponse with .messages list\n",
    "    \n",
    "    Args:\n",
    "        response: Agent response object or string\n",
    "        \n",
    "    Returns:\n",
    "        Extracted text content as string\n",
    "    \"\"\"\n",
    "    if isinstance(response, str):\n",
    "        return response\n",
    "    if hasattr(response, 'text') and response.text:\n",
    "        return response.text\n",
    "    if hasattr(response, 'messages') and response.messages:\n",
    "        last_msg = response.messages[-1]\n",
    "        if hasattr(last_msg, 'content'):\n",
    "            return str(last_msg.content)\n",
    "    return str(response)\n",
    "\n",
    "# =============================================================================\n",
    "# Azure OpenAI Client Setup\n",
    "# =============================================================================\n",
    "\n",
    "# Create token provider for Azure OpenAI with correct scope\n",
    "credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(\n",
    "    credential, \n",
    "    \"https://cognitiveservices.azure.com/.default\"\n",
    ")\n",
    "\n",
    "# Create Azure OpenAI chat client with token provider\n",
    "# Note: The parameter is 'ad_token_provider' not 'azure_ad_token_provider'\n",
    "chat_client = AzureOpenAIChatClient(\n",
    "    ad_token_provider=token_provider,\n",
    "    endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    deployment_name=os.environ[\"AZURE_OPENAI_DEPLOYMENT\"],\n",
    "    api_version=os.environ.get(\"AZURE_OPENAI_VERSION\", \"2024-12-01-preview\"),\n",
    ")\n",
    "\n",
    "print(\"âœ… Microsoft Agent Framework components imported!\")\n",
    "print(f\"âœ… Azure OpenAI client created with deployment: {os.environ['AZURE_OPENAI_DEPLOYMENT']}\")\n",
    "print(\"âœ… Helper function 'extract_response_text()' defined for use in all cells\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c03a0e",
   "metadata": {},
   "source": [
    "## Part 3: Basic Sequential Workflow\n",
    "\n",
    "Let's create a simple sequential workflow using `WorkflowBuilder` and `ChatAgent`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d881fa5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No outgoing edges found for executor step3_agent; dropping messages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step1_agent]: Hello, Workflow!\n",
      "[step1_agent]: [Step 1]: Hello, Workflow! How can I assist you today?\n",
      "[step1_agent]: [AgentExecutorResponse(executor_id='step1_agent', agent_run_response=<agent_framework._types.AgentRu...\n",
      "[step2_agent]: AgentExecutorResponse(executor_id='step1_agent', agent_run_response=<agent_framework._types.AgentRun...\n",
      "[step2_agent]: [Step 2]: Hello, Workflow!\n",
      "[step2_agent]: [AgentExecutorResponse(executor_id='step2_agent', agent_run_response=<agent_framework._types.AgentRu...\n",
      "[step3_agent]: AgentExecutorResponse(executor_id='step2_agent', agent_run_response=<agent_framework._types.AgentRun...\n",
      "[step3_agent]: [Step 3]: Hello, Workflow!\n",
      "[step3_agent]: [AgentExecutorResponse(executor_id='step3_agent', agent_run_response=<agent_framework._types.AgentRu...\n",
      "\n",
      "âœ… Workflow completed in 18765.95ms\n",
      "Final output: [AgentExecutorResponse(executor_id='step3_agent', agent_run_response=<agent_framework._types.AgentRunResponse object at 0x0000013F4B865BB0>, full_conversation=[<agent_framework._types.ChatMessage object at 0x0000013F4B0AE3F0>, <agent_framework._types.ChatMessage object at 0x0000013F4B0AE510>, <agent_framework._types.ChatMessage object at 0x0000013F4B815790>, <agent_framework._types.ChatMessage object at 0x0000013F4B865D30>])]\n"
     ]
    }
   ],
   "source": [
    "# Create specialized agents for each step\n",
    "step1_agent = chat_client.create_agent(\n",
    "    name=\"step1_agent\",\n",
    "    instructions=\"You are Step 1. Add the prefix '[Step 1]:' to the beginning of any message you receive. Return ONLY the prefixed message, nothing else.\"\n",
    ")\n",
    "\n",
    "step2_agent = chat_client.create_agent(\n",
    "    name=\"step2_agent\",\n",
    "    instructions=\"You are Step 2. Add the prefix '[Step 2]:' to the beginning of any message you receive. Return ONLY the prefixed message, nothing else.\"\n",
    ")\n",
    "\n",
    "step3_agent = chat_client.create_agent(\n",
    "    name=\"step3_agent\",\n",
    "    instructions=\"You are Step 3. Add the prefix '[Step 3]:' to the beginning of any message you receive. Return ONLY the prefixed message, nothing else.\"\n",
    ")\n",
    "\n",
    "# Build workflow with sequential edges\n",
    "workflow = (\n",
    "    WorkflowBuilder()\n",
    "    .set_start_executor(step1_agent)\n",
    "    .add_edge(step1_agent, step2_agent)\n",
    "    .add_edge(step2_agent, step3_agent)\n",
    "    .build()\n",
    ")\n",
    "\n",
    "# Execute the workflow\n",
    "import time\n",
    "start = time.time()\n",
    "events = await workflow.run(\"Hello, Workflow!\")\n",
    "duration = (time.time() - start) * 1000\n",
    "\n",
    "# Collect results\n",
    "final_output = None\n",
    "for event in events:\n",
    "    # Only process events that have executor_id (agent events)\n",
    "    if hasattr(event, 'executor_id') and hasattr(event, 'data'):\n",
    "        executor_id = event.executor_id\n",
    "        data = event.data\n",
    "        # Handle AgentRunResponse objects\n",
    "        if hasattr(data, 'text'):\n",
    "            output_text = data.text\n",
    "        elif hasattr(data, 'messages') and data.messages:\n",
    "            # Get text from the last message\n",
    "            last_msg = data.messages[-1]\n",
    "            if hasattr(last_msg, 'content'):\n",
    "                output_text = str(last_msg.content)\n",
    "            else:\n",
    "                output_text = str(last_msg)\n",
    "        else:\n",
    "            output_text = str(data)\n",
    "        final_output = output_text\n",
    "        truncated = output_text[:100] + \"...\" if len(output_text) > 100 else output_text\n",
    "        print(f\"[{executor_id}]: {truncated}\")\n",
    "\n",
    "print(f\"\\nâœ… Workflow completed in {duration:.2f}ms\")\n",
    "print(f\"Final output: {final_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c6816b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Streaming Workflow Execution ===\n",
      "\n",
      "ğŸ“¤ [step1_agent]: Hello, Streaming Workflow!...\n",
      "ğŸ“¤ [step1_agent]: ...\n",
      "ğŸ“¤ [step1_agent]: [...\n",
      "ğŸ“¤ [step1_agent]: Step...\n",
      "ğŸ“¤ [step1_agent]:  ...\n",
      "ğŸ“¤ [step1_agent]: 1...\n",
      "ğŸ“¤ [step1_agent]: ]:...\n",
      "ğŸ“¤ [step1_agent]:  Hello...\n",
      "ğŸ“¤ [step1_agent]: ,...\n",
      "ğŸ“¤ [step1_agent]:  Streaming...\n",
      "ğŸ“¤ [step1_agent]:  Workflow...\n",
      "ğŸ“¤ [step1_agent]: !...\n",
      "ğŸ“¤ [step1_agent]:  How...\n",
      "ğŸ“¤ [step1_agent]:  can...\n",
      "ğŸ“¤ [step1_agent]:  I...\n",
      "ğŸ“¤ [step1_agent]:  assist...\n",
      "ğŸ“¤ [step1_agent]:  you...\n",
      "ğŸ“¤ [step1_agent]:  today...\n",
      "ğŸ“¤ [step1_agent]: ?...\n",
      "ğŸ“¤ [step1_agent]: ...\n",
      "ğŸ“¤ [step1_agent]: ...\n",
      "ğŸ“¤ [step1_agent]: [AgentExecutorResponse(executor_id='step1_agent', agent_run_response=<agent_fram...\n",
      "ğŸ“¤ [step2_agent]: AgentExecutorResponse(executor_id='step1_agent', agent_run_response=<agent_frame...\n",
      "ğŸ“¤ [step2_agent]: ...\n",
      "ğŸ“¤ [step2_agent]: [...\n",
      "ğŸ“¤ [step2_agent]: Step...\n",
      "ğŸ“¤ [step2_agent]:  ...\n",
      "ğŸ“¤ [step2_agent]: 2...\n",
      "ğŸ“¤ [step2_agent]: ]:...\n",
      "ğŸ“¤ [step2_agent]:  Hello...\n",
      "ğŸ“¤ [step2_agent]: ,...\n",
      "ğŸ“¤ [step2_agent]:  Streaming...\n",
      "ğŸ“¤ [step2_agent]:  Workflow...\n",
      "ğŸ“¤ [step2_agent]: !...\n",
      "ğŸ“¤ [step2_agent]: ...\n",
      "ğŸ“¤ [step2_agent]: ...\n",
      "ğŸ“¤ [step2_agent]: [AgentExecutorResponse(executor_id='step2_agent', agent_run_response=<agent_fram...\n",
      "ğŸ“¤ [step3_agent]: AgentExecutorResponse(executor_id='step2_agent', agent_run_response=<agent_frame...\n",
      "ğŸ“¤ [step3_agent]: ...\n",
      "ğŸ“¤ [step3_agent]: [...\n",
      "ğŸ“¤ [step3_agent]: Step...\n",
      "ğŸ“¤ [step3_agent]:  ...\n",
      "ğŸ“¤ [step3_agent]: 3...\n",
      "ğŸ“¤ [step3_agent]: ]:...\n",
      "ğŸ“¤ [step3_agent]:  Hello...\n",
      "ğŸ“¤ [step3_agent]: ,...\n",
      "ğŸ“¤ [step3_agent]:  Streaming...\n",
      "ğŸ“¤ [step3_agent]:  Workflow...\n",
      "ğŸ“¤ [step3_agent]: !...\n",
      "ğŸ“¤ [step3_agent]: ...\n",
      "ğŸ“¤ [step3_agent]: ...\n",
      "ğŸ“¤ [step3_agent]: [AgentExecutorResponse(executor_id='step3_agent', agent_run_response=<agent_fram...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No outgoing edges found for executor step3_agent; dropping messages.\n"
     ]
    }
   ],
   "source": [
    "# Stream workflow events in real-time\n",
    "print(\"=== Streaming Workflow Execution ===\\n\")\n",
    "\n",
    "async for event in workflow.run_stream(\"Hello, Streaming Workflow!\"):\n",
    "    if hasattr(event, 'executor_id') and hasattr(event, 'data'):\n",
    "        data = event.data\n",
    "        # Handle AgentRunResponseUpdate objects\n",
    "        if hasattr(data, 'text'):\n",
    "            output_text = data.text\n",
    "        elif hasattr(data, 'delta') and data.delta:\n",
    "            output_text = str(data.delta)\n",
    "        else:\n",
    "            output_text = str(data)[:80]\n",
    "        print(f\"ğŸ“¤ [{event.executor_id}]: {output_text}...\")\n",
    "    elif hasattr(event, 'type'):\n",
    "        print(f\"ğŸ“ Event: {event.type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6fa91e",
   "metadata": {},
   "source": [
    "## Part 4: Chained Agent Pipelines\n",
    "\n",
    "Create more complex pipelines by chaining multiple agents with `add_edge()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01c6bfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 'hello world'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No outgoing edges found for executor count; dropping messages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 'None'\n",
      "\n",
      "Note: Each agent in the chain processes the output of the previous agent.\n"
     ]
    }
   ],
   "source": [
    "# Create a text processing pipeline with specialized agents\n",
    "\n",
    "uppercase_agent = chat_client.create_agent(\n",
    "    name=\"uppercase\",\n",
    "    instructions=\"Convert the input text to UPPERCASE. Return ONLY the uppercase text.\"\n",
    ")\n",
    "\n",
    "reverse_agent = chat_client.create_agent(\n",
    "    name=\"reverse\",\n",
    "    instructions=\"Reverse the order of characters in the input text. Return ONLY the reversed text.\"\n",
    ")\n",
    "\n",
    "count_agent = chat_client.create_agent(\n",
    "    name=\"count\",\n",
    "    instructions=\"Count the characters in the input and append ' (length: N)' to the text. Return the text with the count.\"\n",
    ")\n",
    "\n",
    "# Build text processing pipeline\n",
    "text_pipeline = (\n",
    "    WorkflowBuilder()\n",
    "    .set_start_executor(uppercase_agent)\n",
    "    .add_edge(uppercase_agent, reverse_agent)\n",
    "    .add_edge(reverse_agent, count_agent)\n",
    "    .build()\n",
    ")\n",
    "\n",
    "# Execute pipeline\n",
    "input_text = \"hello world\"\n",
    "print(f\"Input: '{input_text}'\")\n",
    "\n",
    "events = await text_pipeline.run(input_text)\n",
    "\n",
    "final_result = None\n",
    "for event in events:\n",
    "    if hasattr(event, 'data'):\n",
    "        final_result = event.data\n",
    "\n",
    "print(f\"Output: '{final_result}'\")\n",
    "print(\"\\nNote: Each agent in the chain processes the output of the previous agent.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a46748",
   "metadata": {},
   "source": [
    "## Part 5: Parallel Execution with asyncio.gather()\n",
    "\n",
    "Execute multiple agents concurrently when their operations are independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "708eaffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â±ï¸ Duration: 1743.33ms (parallel execution!)\n",
      "\n",
      "ğŸ“Š Sentiment: {\"sentiment\": \"neutral\", \"confidence\": 0.9}...\n",
      "\n",
      "ğŸ·ï¸ Entities: {\n",
      "  \"entities\": [\n",
      "    {\"text\": \"Apple\", \"type\": \"ORG\"},\n",
      "    {\"text\": \"Tim Cook\", \"type\": \"PERSON\"},\n",
      "...\n",
      "\n",
      "ğŸ“‘ Topics: {\"topics\": [\"Apple\", \"Tim Cook\", \"iPhone announcement\", \"Cupertino\", \"technology\"]}...\n"
     ]
    }
   ],
   "source": [
    "# Parallel agent execution with asyncio.gather()\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "# Create parallel analysis agents\n",
    "sentiment_agent = chat_client.create_agent(\n",
    "    name=\"sentiment\",\n",
    "    instructions=\"Analyze the sentiment of the input text. Return a JSON object with: {\\\"sentiment\\\": \\\"positive|negative|neutral\\\", \\\"confidence\\\": 0.0-1.0}\"\n",
    ")\n",
    "\n",
    "entities_agent = chat_client.create_agent(\n",
    "    name=\"entities\",\n",
    "    instructions=\"Extract named entities from the input text. Return a JSON object with: {\\\"entities\\\": [{\\\"text\\\": \\\"...\\\", \\\"type\\\": \\\"PERSON|ORG|LOCATION\\\"}]}\"\n",
    ")\n",
    "\n",
    "topics_agent = chat_client.create_agent(\n",
    "    name=\"topics\",\n",
    "    instructions=\"Identify the main topics in the input text. Return a JSON object with: {\\\"topics\\\": [\\\"topic1\\\", \\\"topic2\\\", ...]}\"\n",
    ")\n",
    "\n",
    "async def parallel_analysis(text: str) -> dict:\n",
    "    \"\"\"Execute multiple agents in parallel using asyncio.gather().\"\"\"\n",
    "    start = time.time()\n",
    "    \n",
    "    # Run all agents concurrently\n",
    "    results = await asyncio.gather(\n",
    "        sentiment_agent.run(text),\n",
    "        entities_agent.run(text),\n",
    "        topics_agent.run(text),\n",
    "    )\n",
    "    \n",
    "    duration = (time.time() - start) * 1000\n",
    "    \n",
    "    return {\n",
    "        \"sentiment\": extract_response_text(results[0]),\n",
    "        \"entities\": extract_response_text(results[1]),\n",
    "        \"topics\": extract_response_text(results[2]),\n",
    "        \"duration_ms\": duration,\n",
    "    }\n",
    "\n",
    "# Test parallel execution\n",
    "sample_text = \"Apple CEO Tim Cook announced the new iPhone at the company's headquarters in Cupertino, California.\"\n",
    "\n",
    "result = await parallel_analysis(sample_text)\n",
    "\n",
    "print(f\"â±ï¸ Duration: {result['duration_ms']:.2f}ms (parallel execution!)\")\n",
    "print(f\"\\nğŸ“Š Sentiment: {result['sentiment'][:100]}...\")\n",
    "print(f\"\\nğŸ·ï¸ Entities: {result['entities'][:100]}...\")\n",
    "print(f\"\\nğŸ“‘ Topics: {result['topics'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2760f0d",
   "metadata": {},
   "source": [
    "## Part 6: Conditional Branching with add_edge(condition=...)\n",
    "\n",
    "Route to different agents based on runtime conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "722b0acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short text (30 chars): 'AI is transforming industries.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No outgoing edges found for executor expand; dropping messages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[router]: AI is transforming industries....\n",
      "[router]: SHORT...\n",
      "[router]: [AgentExecutorResponse(executor_id='router', agent_run_response=<agent_framework._types.AgentRunResponse object at 0x0000013F4B8DFDD0>, full_conversat...\n",
      "[expand]: SHORT...\n",
      "[expand]: AI is revolutionizing various industries by enhancing efficiency, accuracy, and innovation. In sectors like healthcare, finance, and manufacturing, AI...\n",
      "[expand]: [AgentExecutorResponse(executor_id='expand', agent_run_response=<agent_framework._types.AgentRunResponse object at 0x0000013F4B8DC710>, full_conversat...\n",
      "\n",
      "Long text (285 chars): 'Artificial intelligence has been making remarkable...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No outgoing edges found for executor summarize; dropping messages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[router]: Artificial intelligence has been making remarkable strides in recent years, with applications spanning healthcare, finance, transportation, and entert...\n",
      "[router]: LONG...\n",
      "[router]: [AgentExecutorResponse(executor_id='router', agent_run_response=<agent_framework._types.AgentRunResponse object at 0x0000013F4B8DC3B0>, full_conversat...\n",
      "[summarize]: LONG...\n",
      "[summarize]: Artificial intelligence has advanced significantly, impacting sectors like healthcare, finance, transportation, and entertainment. Machine learning al...\n",
      "[summarize]: [AgentExecutorResponse(executor_id='summarize', agent_run_response=<agent_framework._types.AgentRunResponse object at 0x0000013F4B9100B0>, full_conver...\n"
     ]
    }
   ],
   "source": [
    "# Create router and specialized agents\n",
    "router_agent = chat_client.create_agent(\n",
    "    name=\"router\",\n",
    "    instructions=\"Determine if the input text is long (>100 chars) or short. Return exactly 'LONG' or 'SHORT'.\"\n",
    ")\n",
    "\n",
    "summarize_agent = chat_client.create_agent(\n",
    "    name=\"summarize\",\n",
    "    instructions=\"Summarize the long text into 2-3 sentences. Be concise.\"\n",
    ")\n",
    "\n",
    "expand_agent = chat_client.create_agent(\n",
    "    name=\"expand\",\n",
    "    instructions=\"Expand the short text into a more detailed explanation (3-4 sentences).\"\n",
    ")\n",
    "\n",
    "def extract_text_from_response(data) -> str:\n",
    "    \"\"\"Extract text from AgentExecutorResponse or string.\"\"\"\n",
    "    if isinstance(data, str):\n",
    "        return data\n",
    "    if hasattr(data, 'agent_run_response'):\n",
    "        response = data.agent_run_response\n",
    "        if hasattr(response, 'text') and response.text:\n",
    "            return response.text\n",
    "        if hasattr(response, 'messages') and response.messages:\n",
    "            last_msg = response.messages[-1]\n",
    "            if hasattr(last_msg, 'content'):\n",
    "                return str(last_msg.content)\n",
    "    return str(data)\n",
    "\n",
    "# Define condition functions that work with AgentExecutorResponse\n",
    "def is_long_text(data) -> bool:\n",
    "    \"\"\"Check if router response indicates LONG.\"\"\"\n",
    "    text = extract_text_from_response(data)\n",
    "    return \"LONG\" in text.upper()\n",
    "\n",
    "def is_short_text(data) -> bool:\n",
    "    \"\"\"Check if router response indicates SHORT.\"\"\"\n",
    "    text = extract_text_from_response(data)\n",
    "    return \"SHORT\" in text.upper()\n",
    "\n",
    "# Build conditional workflow\n",
    "conditional_workflow = (\n",
    "    WorkflowBuilder()\n",
    "    .set_start_executor(router_agent)\n",
    "    .add_edge(router_agent, summarize_agent, condition=is_long_text)\n",
    "    .add_edge(router_agent, expand_agent, condition=is_short_text)\n",
    "    .build()\n",
    ")\n",
    "\n",
    "# Test with short text\n",
    "short_text = \"AI is transforming industries.\"\n",
    "print(f\"Short text ({len(short_text)} chars): '{short_text}'\")\n",
    "events = await conditional_workflow.run(short_text)\n",
    "for event in events:\n",
    "    if hasattr(event, 'executor_id') and hasattr(event, 'data'):\n",
    "        text = extract_text_from_response(event.data)\n",
    "        print(f\"[{event.executor_id}]: {text[:150]}...\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Test with long text\n",
    "long_text = \"Artificial intelligence has been making remarkable strides in recent years, with applications spanning healthcare, finance, transportation, and entertainment. Machine learning algorithms are now capable of diagnosing diseases, predicting market trends, and driving autonomous vehicles.\"\n",
    "print(f\"Long text ({len(long_text)} chars): '{long_text[:50]}...'\")\n",
    "events = await conditional_workflow.run(long_text)\n",
    "for event in events:\n",
    "    if hasattr(event, 'executor_id') and hasattr(event, 'data'):\n",
    "        text = extract_text_from_response(event.data)\n",
    "        print(f\"[{event.executor_id}]: {text[:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7013b87e",
   "metadata": {},
   "source": [
    "## Part 7: Data Transformation Between Agents\n",
    "\n",
    "Pass structured data between agents using prompt templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67ec02ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: The artificial intelligence revolution is transfor...\n",
      "Keywords: ['artificial intelligence', 'revolution', 'machine learning', 'deep neural networks', 'industries']\n",
      "Count: 5\n"
     ]
    }
   ],
   "source": [
    "# Data transformation through prompt templates\n",
    "\n",
    "keyword_extractor = chat_client.create_agent(\n",
    "    name=\"keyword_extractor\",\n",
    "    instructions=\"\"\"Extract the top 5 keywords from the input text.\n",
    "Return ONLY a comma-separated list of keywords, nothing else.\n",
    "Example: keyword1, keyword2, keyword3, keyword4, keyword5\"\"\"\n",
    ")\n",
    "\n",
    "def get_text_from_run_response(response) -> str:\n",
    "    \"\"\"Extract text from AgentRunResponse.\"\"\"\n",
    "    if hasattr(response, 'text') and response.text:\n",
    "        return response.text\n",
    "    if hasattr(response, 'messages') and response.messages:\n",
    "        last_msg = response.messages[-1]\n",
    "        if hasattr(last_msg, 'content'):\n",
    "            return str(last_msg.content)\n",
    "    return str(response)\n",
    "\n",
    "async def extract_and_transform(text: str) -> dict:\n",
    "    \"\"\"Extract keywords and return structured data.\"\"\"\n",
    "    # Run keyword extraction\n",
    "    result = await keyword_extractor.run(text)\n",
    "    \n",
    "    # Transform response to structured format\n",
    "    result_text = get_text_from_run_response(result)\n",
    "    keywords = [k.strip() for k in result_text.split(',')]\n",
    "    \n",
    "    return {\n",
    "        \"original_text\": text[:50] + \"...\",\n",
    "        \"keywords\": keywords[:5],\n",
    "        \"keyword_count\": len(keywords),\n",
    "    }\n",
    "\n",
    "# Test data transformation\n",
    "sample = \"The artificial intelligence revolution is transforming industries worldwide through machine learning and deep neural networks.\"\n",
    "\n",
    "result = await extract_and_transform(sample)\n",
    "\n",
    "print(f\"Original: {result['original_text']}\")\n",
    "print(f\"Keywords: {result['keywords']}\")\n",
    "print(f\"Count: {result['keyword_count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f0ceca",
   "metadata": {},
   "source": [
    "## Part 8: Error Handling with Middleware\n",
    "\n",
    "Use middleware patterns for retry logic and error handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f23ab915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Middleware patterns defined\n"
     ]
    }
   ],
   "source": [
    "# Define a retry middleware for agent calls\n",
    "import asyncio\n",
    "from typing import Callable, Any\n",
    "\n",
    "class RetryMiddleware:\n",
    "    \"\"\"Middleware that retries failed agent calls with exponential backoff.\"\"\"\n",
    "    \n",
    "    def __init__(self, max_retries: int = 3, base_delay: float = 1.0, max_delay: float = 10.0):\n",
    "        self.max_retries = max_retries\n",
    "        self.base_delay = base_delay\n",
    "        self.max_delay = max_delay\n",
    "    \n",
    "    async def execute(self, func: Callable, *args, **kwargs) -> Any:\n",
    "        \"\"\"Execute function with retry logic.\"\"\"\n",
    "        delay = self.base_delay\n",
    "        last_error = None\n",
    "        \n",
    "        for attempt in range(self.max_retries + 1):\n",
    "            try:\n",
    "                return await func(*args, **kwargs)\n",
    "            except Exception as e:\n",
    "                last_error = e\n",
    "                if attempt < self.max_retries:\n",
    "                    print(f\"âš ï¸ Attempt {attempt + 1} failed: {e}\")\n",
    "                    print(f\"   Retrying in {delay:.1f}s...\")\n",
    "                    await asyncio.sleep(delay)\n",
    "                    delay = min(delay * 2, self.max_delay)\n",
    "        \n",
    "        raise last_error\n",
    "\n",
    "# Example: Safe workflow wrapper with error handling\n",
    "async def safe_agent_call(agent, prompt: str, fallback: str = \"Unable to process request.\"):\n",
    "    \"\"\"Execute agent with fallback on failure.\"\"\"\n",
    "    try:\n",
    "        return await agent.run(prompt)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Agent call failed: {e}\")\n",
    "        return fallback\n",
    "\n",
    "print(\"âœ… Middleware patterns defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f71545c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords: product launch, success, huge, event, announcement...\n",
      "Sentiment: {\"sentiment\": \"positive\", \"confidence\": 0.95}...\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate safe workflow execution with error handling\n",
    "\n",
    "async def robust_workflow(text: str) -> dict:\n",
    "    \"\"\"Execute a workflow with comprehensive error handling.\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Step 1: Extract keywords with fallback\n",
    "    keyword_result = await safe_agent_call(\n",
    "        keyword_extractor,\n",
    "        text,\n",
    "        fallback=\"keyword extraction failed\"\n",
    "    )\n",
    "    results[\"keywords\"] = get_text_from_run_response(keyword_result) if hasattr(keyword_result, 'messages') else keyword_result\n",
    "    \n",
    "    # Step 2: Analyze sentiment with fallback\n",
    "    sentiment_result = await safe_agent_call(\n",
    "        sentiment_agent,\n",
    "        text,\n",
    "        fallback='{\"sentiment\": \"unknown\", \"confidence\": 0.0}'\n",
    "    )\n",
    "    results[\"sentiment\"] = get_text_from_run_response(sentiment_result) if hasattr(sentiment_result, 'messages') else sentiment_result\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test robust workflow\n",
    "result = await robust_workflow(\"The product launch was a huge success!\")\n",
    "print(f\"Keywords: {result['keywords'][:80]}...\")\n",
    "print(f\"Sentiment: {result['sentiment'][:80]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "868b84f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Circuit breaker initialized (state: CLOSED)\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate circuit breaker pattern for resilience\n",
    "\n",
    "class CircuitBreaker:\n",
    "    \"\"\"Simple circuit breaker to prevent cascading failures.\"\"\"\n",
    "    \n",
    "    def __init__(self, failure_threshold: int = 3, reset_timeout: float = 30.0):\n",
    "        self.failure_threshold = failure_threshold\n",
    "        self.reset_timeout = reset_timeout\n",
    "        self.failures = 0\n",
    "        self.last_failure_time = None\n",
    "        self.state = \"CLOSED\"  # CLOSED, OPEN, HALF_OPEN\n",
    "    \n",
    "    def can_execute(self) -> bool:\n",
    "        \"\"\"Check if execution is allowed.\"\"\"\n",
    "        if self.state == \"CLOSED\":\n",
    "            return True\n",
    "        \n",
    "        if self.state == \"OPEN\":\n",
    "            import time\n",
    "            if time.time() - self.last_failure_time > self.reset_timeout:\n",
    "                self.state = \"HALF_OPEN\"\n",
    "                return True\n",
    "            return False\n",
    "        \n",
    "        return True  # HALF_OPEN allows one attempt\n",
    "    \n",
    "    def record_success(self):\n",
    "        \"\"\"Record successful execution.\"\"\"\n",
    "        self.failures = 0\n",
    "        self.state = \"CLOSED\"\n",
    "    \n",
    "    def record_failure(self):\n",
    "        \"\"\"Record failed execution.\"\"\"\n",
    "        import time\n",
    "        self.failures += 1\n",
    "        self.last_failure_time = time.time()\n",
    "        \n",
    "        if self.failures >= self.failure_threshold:\n",
    "            self.state = \"OPEN\"\n",
    "            print(f\"ğŸ”´ Circuit breaker OPEN (failures: {self.failures})\")\n",
    "\n",
    "circuit_breaker = CircuitBreaker()\n",
    "print(f\"âœ… Circuit breaker initialized (state: {circuit_breaker.state})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7baf4d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: success\n",
      "Result: {\"sentiment\": \"positive\", \"confidence\": 0.95}...\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate timeout handling for agent calls\n",
    "\n",
    "def extract_text(response) -> str:\n",
    "    \"\"\"Extract text from AgentRunResponse or return string.\"\"\"\n",
    "    if isinstance(response, str):\n",
    "        return response\n",
    "    if hasattr(response, 'text') and response.text:\n",
    "        return response.text\n",
    "    if hasattr(response, 'messages') and response.messages:\n",
    "        last_msg = response.messages[-1]\n",
    "        if hasattr(last_msg, 'content'):\n",
    "            return str(last_msg.content)\n",
    "    return str(response)\n",
    "\n",
    "async def agent_with_timeout(agent, prompt: str, timeout_seconds: float = 30.0):\n",
    "    \"\"\"Execute agent with timeout.\"\"\"\n",
    "    try:\n",
    "        result = await asyncio.wait_for(\n",
    "            agent.run(prompt),\n",
    "            timeout=timeout_seconds\n",
    "        )\n",
    "        return {\"status\": \"success\", \"result\": extract_text(result)}\n",
    "    except asyncio.TimeoutError:\n",
    "        return {\"status\": \"timeout\", \"result\": f\"Agent timed out after {timeout_seconds}s\"}\n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"result\": str(e)}\n",
    "\n",
    "# Test timeout handling\n",
    "result = await agent_with_timeout(\n",
    "    sentiment_agent,\n",
    "    \"This is a great day!\",\n",
    "    timeout_seconds=30.0\n",
    ")\n",
    "\n",
    "print(f\"Status: {result['status']}\")\n",
    "print(f\"Result: {result['result'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6cba39",
   "metadata": {},
   "source": [
    "## Part 9: Retry Strategies with Middleware\n",
    "\n",
    "The Agent Framework uses middleware patterns for cross-cutting concerns like retries. We've implemented a `RetryMiddleware` that can be composed with any agent call.\n",
    "\n",
    "Key benefits:\n",
    "- **Composable**: Wrap any agent call with retry behavior\n",
    "- **Configurable**: Customize retry counts, delays, and conditions\n",
    "- **Transparent**: The underlying agent code doesn't need to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25c41c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Attempt 1 failed: Simulated failure on call #1\n",
      "   Retrying in 0.1s...\n",
      "âš ï¸ Attempt 2 failed: Simulated failure on call #2\n",
      "   Retrying in 0.2s...\n",
      "âœ“ Success on call #3: Processed 'Please analyze this important ...'\n",
      "Total API calls: 3\n"
     ]
    }
   ],
   "source": [
    "# Simulate a flaky operation and test retry middleware\n",
    "\n",
    "import random\n",
    "\n",
    "class FlakyAgent:\n",
    "    \"\"\"Agent that randomly fails to demonstrate retry patterns.\"\"\"\n",
    "    \n",
    "    def __init__(self, failure_rate: float = 0.7):\n",
    "        self.failure_rate = failure_rate\n",
    "        self.call_count = 0\n",
    "    \n",
    "    async def run(self, prompt: str) -> str:\n",
    "        self.call_count += 1\n",
    "        if random.random() < self.failure_rate:\n",
    "            raise Exception(f\"Simulated failure on call #{self.call_count}\")\n",
    "        return f\"Success on call #{self.call_count}: Processed '{prompt[:30]}...'\"\n",
    "\n",
    "# Create flaky agent and retry middleware\n",
    "flaky_agent = FlakyAgent(failure_rate=0.7)\n",
    "retry_middleware = RetryMiddleware(max_retries=5, base_delay=0.1, max_delay=1.0)\n",
    "\n",
    "# Execute with retry\n",
    "async def run_with_retry():\n",
    "    return await retry_middleware.execute(\n",
    "        flaky_agent.run,\n",
    "        \"Please analyze this important data\"\n",
    "    )\n",
    "\n",
    "try:\n",
    "    result = await run_with_retry()\n",
    "    print(f\"âœ“ {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"âœ— Failed after all retries: {e}\")\n",
    "\n",
    "print(f\"Total API calls: {flaky_agent.call_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea3edda",
   "metadata": {},
   "source": [
    "## Part 10: The Framework's WorkflowBuilder Pattern\n",
    "\n",
    "The Microsoft Agent Framework provides a `WorkflowBuilder` class that enables declarative workflow construction. Here's the complete pattern for building complex workflows:\n",
    "\n",
    "```python\n",
    "# The canonical pattern for Agent Framework workflows:\n",
    "workflow = (\n",
    "    WorkflowBuilder()\n",
    "    .set_start_executor(agent_1)\n",
    "    .add_edge(agent_1, agent_2)\n",
    "    .add_edge(agent_2, agent_3, condition=some_condition)\n",
    "    .build()\n",
    ")\n",
    "```\n",
    "\n",
    "**Key Components**:\n",
    "- `set_start_executor()`: Define the entry point\n",
    "- `add_edge()`: Create connections between agents\n",
    "- `condition=`: Add conditional routing\n",
    "- `build()`: Finalize the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "474abf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Complete Analysis Workflow ===\n",
      "\n",
      "Input Text:\n",
      "\n",
      "Q3 2024 Results: Revenue increased 15% YoY to $2.4B.\n",
      "Operating margin improved to 28%. Cloud services grew 45%.\n",
      "New customer acquisition up 22% with 95% retention rate.\n",
      "\n",
      "\n",
      "1. Extraction:\n",
      "- Quarter: Q3 2024  \n",
      "- Revenue: $2.4 billion  \n",
      "- Revenue growth: 15% year-over-year (YoY)  \n",
      "- Operating margin: 28%  \n",
      "- Cloud services growth: 45%  \n",
      "- New customer acquisition growth: 22%  \n",
      "- Customer retention rate: 95%\n",
      "\n",
      "2. Analysis:\n",
      "Based on the extracted facts for Q3 2024, here is the analysis and conclusions:\n",
      "\n",
      "1. **Strong Revenue Growth:**  \n",
      "   - The company generated $2.4 billion in revenue in Q3 2024, reflecting a 15% year-over-year increase.  \n",
      "   - This indicates healthy overall business expansion and market demand.\n",
      "\n",
      "2. **High Operating Margin:**  \n",
      "   - An operating margin of 28% suggests operational efficiency and effective cost management.  \n",
      "   - This margin is relatively high, demonstrating profitability and strong control over operating expenses.\n",
      "\n",
      "3. **Cloud Services as a Growth Driver:**  \n",
      "   - Cloud services grew by 45%, significantly outpacing the overall revenue growth of 15%.  \n",
      "   - This implies a strategic focus on cloud offerings that are resonating well with customers and contributing disproportionately to revenue growth.\n",
      "\n",
      "4. **Effective Market Expansion:**  \n",
      "   - New customer acquisition growth of 22% shows successful efforts in onboarding new clients.  \n",
      "   - This is higher than the overall revenue growth rate, which might suggest capturing new business segments or geographies.\n",
      "\n",
      "5. **Strong Customer Loyalty:**  \n",
      "   - A 95% customer retention rate indicates high satisfaction and stickiness of the customer base.  \n",
      "   - Retaining existing customers helps sustain recurring revenues and reduces churn-related losses.\n",
      "\n",
      "**Conclusions:**  \n",
      "- The company is experiencing robust growth, driven largely by its cloud services segment.  \n",
      "- Operational efficiency is strong as indicated by a high operating margin.  \n",
      "- Growth is balanced between acquiring new customers and maintaining existing ones, providing a solid foundation for sustained future performance.  \n",
      "- The company appears well-positioned in the market with scalable offerings and strong financial health.\n",
      "\n",
      "3. Final Output:\n",
      "**Q3 2024 Financial and Operational Analysis**\n",
      "\n",
      "**1. Strong Revenue Growth**  \n",
      "- The company reported revenue of $2.4 billion in Q3 2024, representing a 15% year-over-year increase.  \n",
      "- This growth reflects robust overall business expansion and sustained market demand.\n",
      "\n",
      "**2. High Operating Margin**  \n",
      "- An operating margin of 28% highlights operational efficiency and effective cost management.  \n",
      "- This relatively high margin underscores strong profitability and disciplined control over operating expenses.\n",
      "\n",
      "**3. Cloud Services as a Key Growth Driver**  \n",
      "- Cloud services revenue surged by 45%, significantly surpassing the overall revenue growth rate of 15%.  \n",
      "- This indicates a strategic emphasis on cloud offerings, which are resonating strongly with customers and contributing disproportionately to revenue growth.\n",
      "\n",
      "**4. Effective Market Expansion**  \n",
      "- New customer acquisition increased by 22%, outpacing overall revenue growth.  \n",
      "- This suggests successful penetration into new business segments or geographic markets.\n",
      "\n",
      "**5. Strong Customer Loyalty**  \n",
      "- A customer retention rate of 95% reflects high satisfaction and loyalty within the customer base.  \n",
      "- Maintaining such retention supports recurring revenues and minimizes churn-related losses.\n",
      "\n",
      "---\n",
      "\n",
      "**Conclusions**  \n",
      "- The company is demonstrating robust growth, primarily driven by its expanding cloud services segment.  \n",
      "- Operational efficiency remains strong, as evidenced by a healthy operating margin.  \n",
      "- Balanced growth in both new customer acquisition and retention establishes a solid platform for sustained future performance.  \n",
      "- Overall, the company is well-positioned in the market with scalable product offerings and strong financial health.\n"
     ]
    }
   ],
   "source": [
    "# Build a complete analysis workflow using WorkflowBuilder\n",
    "\n",
    "# Create specialized agents for different analysis tasks\n",
    "extract_agent = chat_client.create_agent(\n",
    "    name=\"Extractor\",\n",
    "    instructions=\"You are a data extraction specialist. Extract key facts from text.\"\n",
    ")\n",
    "\n",
    "analyze_agent = chat_client.create_agent(\n",
    "    name=\"Analyzer\", \n",
    "    instructions=\"You are an analytical AI. Analyze patterns and draw conclusions.\"\n",
    ")\n",
    "\n",
    "format_agent = chat_client.create_agent(\n",
    "    name=\"Formatter\",\n",
    "    instructions=\"You are a formatting specialist. Format analysis results professionally.\"\n",
    ")\n",
    "\n",
    "# Build workflow with chained agents\n",
    "analysis_workflow = (\n",
    "    WorkflowBuilder()\n",
    "    .set_start_executor(extract_agent)\n",
    "    .add_edge(extract_agent, analyze_agent)\n",
    "    .add_edge(analyze_agent, format_agent)\n",
    "    .build()\n",
    ")\n",
    "\n",
    "# Execute the workflow\n",
    "sample_text = \"\"\"\n",
    "Q3 2024 Results: Revenue increased 15% YoY to $2.4B.\n",
    "Operating margin improved to 28%. Cloud services grew 45%.\n",
    "New customer acquisition up 22% with 95% retention rate.\n",
    "\"\"\"\n",
    "\n",
    "print(\"=== Complete Analysis Workflow ===\\n\")\n",
    "print(f\"Input Text:\\n{sample_text}\\n\")\n",
    "\n",
    "# Run extraction\n",
    "extract_result = await extract_agent.run(f\"Extract key metrics from: {sample_text}\")\n",
    "print(f\"1. Extraction:\\n{extract_result}\\n\")\n",
    "\n",
    "# Run analysis\n",
    "analyze_result = await analyze_agent.run(f\"Analyze these extracted facts: {extract_result}\")\n",
    "print(f\"2. Analysis:\\n{analyze_result}\\n\")\n",
    "\n",
    "# Run formatting\n",
    "format_result = await format_agent.run(f\"Format this analysis professionally: {analyze_result}\")\n",
    "print(f\"3. Final Output:\\n{format_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0245b31",
   "metadata": {},
   "source": [
    "## Part 11: Workflow Validation and Testing\n",
    "\n",
    "When building deterministic workflows, validation is critical:\n",
    "\n",
    "1. **Pre-execution validation**: Check all agents are properly configured\n",
    "2. **Runtime monitoring**: Track execution through each step\n",
    "3. **Post-execution validation**: Verify outputs meet expectations\n",
    "\n",
    "The Agent Framework's approach makes testing easier because each component is independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4947a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Workflow Validation ===\n",
      "\n",
      "Overall: âœ“ PASS\n",
      "Summary: 6/6 agents valid\n",
      "\n",
      "  âœ“ sentiment: OK\n",
      "  âœ“ entities: OK\n",
      "  âœ“ topics: OK\n",
      "  âœ“ Extractor: OK\n",
      "  âœ“ Analyzer: OK\n",
      "  âœ“ Formatter: OK\n"
     ]
    }
   ],
   "source": [
    "# Workflow validation utilities\n",
    "\n",
    "def validate_agent(agent) -> dict:\n",
    "    \"\"\"Validate agent configuration before workflow execution.\"\"\"\n",
    "    issues = []\n",
    "    agent_name = getattr(agent, 'name', 'Unknown')\n",
    "    \n",
    "    # Check required attributes\n",
    "    if not agent_name or agent_name == 'Unknown':\n",
    "        issues.append(\"Agent missing name\")\n",
    "    \n",
    "    # Check if agent has run method\n",
    "    if not hasattr(agent, 'run') or not callable(getattr(agent, 'run', None)):\n",
    "        issues.append(\"Agent missing run() method\")\n",
    "    \n",
    "    return {\n",
    "        \"agent\": agent_name,\n",
    "        \"valid\": len(issues) == 0,\n",
    "        \"issues\": issues\n",
    "    }\n",
    "\n",
    "def validate_workflow_agents(*agents) -> dict:\n",
    "    \"\"\"Validate all agents in a workflow.\"\"\"\n",
    "    results = [validate_agent(a) for a in agents]\n",
    "    all_valid = all(r[\"valid\"] for r in results)\n",
    "    \n",
    "    return {\n",
    "        \"valid\": all_valid,\n",
    "        \"agent_results\": results,\n",
    "        \"summary\": f\"{sum(1 for r in results if r['valid'])}/{len(results)} agents valid\"\n",
    "    }\n",
    "\n",
    "# Validate our workflow agents\n",
    "validation = validate_workflow_agents(\n",
    "    sentiment_agent,\n",
    "    entities_agent,\n",
    "    topics_agent,\n",
    "    extract_agent,\n",
    "    analyze_agent,\n",
    "    format_agent\n",
    ")\n",
    "\n",
    "print(\"=== Workflow Validation ===\\n\")\n",
    "print(f\"Overall: {'âœ“ PASS' if validation['valid'] else 'âœ— FAIL'}\")\n",
    "print(f\"Summary: {validation['summary']}\\n\")\n",
    "\n",
    "for result in validation['agent_results']:\n",
    "    status = \"âœ“\" if result['valid'] else \"âœ—\"\n",
    "    print(f\"  {status} {result['agent']}: {'OK' if result['valid'] else result['issues']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe21835",
   "metadata": {},
   "source": [
    "## Part 12: Hands-on Exercise\n",
    "\n",
    "**Challenge**: Build a content moderation workflow using the patterns learned.\n",
    "\n",
    "Your workflow should:\n",
    "1. **Classify** content (safe/unsafe) using a classification agent\n",
    "2. **Route** based on classification (conditional logic)\n",
    "3. **Process** safe content through enhancement\n",
    "4. **Flag** unsafe content for review\n",
    "\n",
    "Use the Microsoft Agent Framework patterns:\n",
    "- `ChatAgent` for each processing step\n",
    "- `asyncio.gather()` if parallel processing needed\n",
    "- Conditional routing with if/else based on agent output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f956038c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Content Moderation Workflow ===\n",
      "\n",
      "Input: Our Q3 earnings exceeded expectations with 15% gro...\n",
      "Status: APPROVED\n",
      "Classification: SAFE\n",
      "Output: Our Q3 earnings surpassed expectations, achieving an impressive 15% growth....\n",
      "\n",
      "Input: Meeting scheduled for Tuesday to discuss project t...\n",
      "Status: APPROVED\n",
      "Classification: SAFE\n",
      "Output: A meeting is scheduled for Tuesday to discuss and finalize the project timeline....\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exercise: Build a content moderation workflow\n",
    "\n",
    "def get_response_text(response) -> str:\n",
    "    \"\"\"Extract text from AgentRunResponse.\"\"\"\n",
    "    if isinstance(response, str):\n",
    "        return response\n",
    "    if hasattr(response, 'text') and response.text:\n",
    "        return response.text\n",
    "    if hasattr(response, 'messages') and response.messages:\n",
    "        last_msg = response.messages[-1]\n",
    "        if hasattr(last_msg, 'content'):\n",
    "            return str(last_msg.content)\n",
    "    return str(response)\n",
    "\n",
    "# Step 1: Create the agents\n",
    "classifier_agent = chat_client.create_agent(\n",
    "    name=\"Classifier\",\n",
    "    instructions=\"\"\"You are a content classifier. \n",
    "    Analyze text and respond with exactly one word: SAFE or UNSAFE.\n",
    "    SAFE = appropriate professional content\n",
    "    UNSAFE = inappropriate, harmful, or policy-violating content\"\"\"\n",
    ")\n",
    "\n",
    "enhancer_agent = chat_client.create_agent(\n",
    "    name=\"Enhancer\",\n",
    "    instructions=\"You are a content enhancer. Improve the quality and clarity of safe content.\"\n",
    ")\n",
    "\n",
    "flagger_agent = chat_client.create_agent(\n",
    "    name=\"Flagger\",\n",
    "    instructions=\"You are a content reviewer. Document why content was flagged and suggest remediation.\"\n",
    ")\n",
    "\n",
    "# Step 2: Build the moderation workflow\n",
    "async def moderate_content(content: str) -> dict:\n",
    "    \"\"\"Content moderation workflow using Agent Framework patterns.\"\"\"\n",
    "    \n",
    "    # Classify content\n",
    "    classification_response = await classifier_agent.run(f\"Classify this content: {content}\")\n",
    "    classification_text = get_response_text(classification_response)\n",
    "    is_safe = \"SAFE\" in classification_text.upper()\n",
    "    \n",
    "    # Route based on classification\n",
    "    if is_safe:\n",
    "        # Process safe content\n",
    "        enhanced = await enhancer_agent.run(f\"Enhance this content: {content}\")\n",
    "        return {\n",
    "            \"status\": \"approved\",\n",
    "            \"classification\": \"SAFE\",\n",
    "            \"result\": get_response_text(enhanced)\n",
    "        }\n",
    "    else:\n",
    "        # Flag unsafe content\n",
    "        flag_report = await flagger_agent.run(f\"Review and document why this is flagged: {content}\")\n",
    "        return {\n",
    "            \"status\": \"flagged\",\n",
    "            \"classification\": \"UNSAFE\",\n",
    "            \"result\": get_response_text(flag_report)\n",
    "        }\n",
    "\n",
    "# Test the workflow\n",
    "test_contents = [\n",
    "    \"Our Q3 earnings exceeded expectations with 15% growth.\",\n",
    "    \"Meeting scheduled for Tuesday to discuss project timeline.\"\n",
    "]\n",
    "\n",
    "print(\"=== Content Moderation Workflow ===\\n\")\n",
    "for content in test_contents:\n",
    "    print(f\"Input: {content[:50]}...\")\n",
    "    result = await moderate_content(content)\n",
    "    print(f\"Status: {result['status'].upper()}\")\n",
    "    print(f\"Classification: {result['classification']}\")\n",
    "    print(f\"Output: {result['result'][:100]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0acfcd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we explored deterministic workflow orchestration using the **Microsoft Agent Framework**:\n",
    "\n",
    "### Key Patterns Learned:\n",
    "\n",
    "| Custom Code | Agent Framework Equivalent |\n",
    "|-------------|---------------------------|\n",
    "| `WorkflowEngine.add_step()` | `WorkflowBuilder().add_edge()` |\n",
    "| `SequentialStep([steps])` | Chained `add_edge()` calls |\n",
    "| `ParallelStep([steps])` | `asyncio.gather()` with agents |\n",
    "| `ConditionalStep(cond, a, b)` | `add_edge(condition=fn)` |\n",
    "| `RetryConfig` | `RetryMiddleware` pattern |\n",
    "| `ErrorStrategy` enum | `CircuitBreaker` pattern |\n",
    "\n",
    "### Framework Benefits:\n",
    "- **Less custom code**: Leverage battle-tested framework components\n",
    "- **Standard patterns**: Use industry-standard async patterns\n",
    "- **Composability**: Combine agents and middleware flexibly\n",
    "- **Testability**: Each component is independently testable\n",
    "\n",
    "### Next Steps:\n",
    "- **Notebook 05**: Declarative agent configuration with YAML\n",
    "- **Notebook 06**: Multi-agent discussions and collaboration\n",
    "- **Notebook 07**: Evaluation and prompt evolution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (agents-workshop)",
   "language": "python",
   "name": "agents-workshop-312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
