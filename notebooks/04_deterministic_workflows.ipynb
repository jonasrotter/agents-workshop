{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c3165f6",
   "metadata": {},
   "source": [
    "# Scenario 04: Deterministic Multi-Agent Workflows\n",
    "\n",
    "**Estimated Time**: 45 minutes\n",
    "\n",
    "## Learning Objectives\n",
    "- Design deterministic workflows using Microsoft Agent Framework's `WorkflowBuilder`\n",
    "- Implement sequential agent chains with `add_edge()`\n",
    "- Execute parallel agent operations with `asyncio.gather()`\n",
    "- Handle conditional routing with condition functions\n",
    "- Use middleware patterns for error handling and retry logic\n",
    "\n",
    "## Prerequisites\n",
    "- Completed Scenario 01 (Simple Agent + MCP)\n",
    "- Understanding of async/await patterns in Python\n",
    "- Azure OpenAI access configured in `.env`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3eba18",
   "metadata": {},
   "source": [
    "## Part 1: Understanding Deterministic Workflows\n",
    "\n",
    "### What Are Deterministic Workflows?\n",
    "\n",
    "Deterministic workflows define a **fixed execution path** for coordinating multiple agents:\n",
    "\n",
    "- **Predictable**: Same inputs produce same execution order\n",
    "- **Debuggable**: Clear step-by-step execution trace\n",
    "- **Testable**: Each step can be tested independently\n",
    "- **Recoverable**: Built-in error handling and retry logic\n",
    "\n",
    "### Microsoft Agent Framework Approach\n",
    "\n",
    "Instead of building custom workflow engines, we use the official `WorkflowBuilder` API:\n",
    "\n",
    "| Custom Approach | Agent Framework |\n",
    "|-----------------|-----------------|\n",
    "| `WorkflowEngine.add_step()` | `WorkflowBuilder.add_edge()` |\n",
    "| `SequentialStep` container | Chained `add_edge()` calls |\n",
    "| `ParallelStep` container | `asyncio.gather()` with agents |\n",
    "| `ConditionalStep` | `add_edge(condition=fn)` |\n",
    "| Custom error strategies | Middleware patterns |\n",
    "\n",
    "### When to Use Deterministic Workflows\n",
    "\n",
    "- ETL pipelines with agent transformations\n",
    "- Document processing (extract ‚Üí analyze ‚Üí summarize)\n",
    "- Research workflows (search ‚Üí analyze ‚Üí report)\n",
    "- Approval workflows with human-in-the-loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9501b82a",
   "metadata": {},
   "source": [
    "## Part 2: Setting Up the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50230242-2614-417f-8abc-bb7b1bf407f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Removed AZURE_OPENAI_API_KEY from environment to force Entra ID auth\n",
      "‚úÖ Project root: C:\\Users\\jonasrotter\\OneDrive - Microsoft\\Desktop\\Jonas Privat\\MyCodingProjects\\agents-workshop\n",
      "‚úÖ Azure OpenAI endpoint: https://aistudiojonasr5312406741.openai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "# Load environment and configure paths\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path(\"..\").resolve()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Load environment variables (force override cached values)\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(project_root / \".env\", override=True)\n",
    "\n",
    "# IMPORTANT: Remove API key from env to force Entra ID auth\n",
    "if \"AZURE_OPENAI_API_KEY\" in os.environ:\n",
    "    del os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "    print(\"‚ö†Ô∏è Removed AZURE_OPENAI_API_KEY from environment to force Entra ID auth\")\n",
    "\n",
    "# Verify Azure OpenAI configuration\n",
    "assert os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \"Missing AZURE_OPENAI_ENDPOINT\"\n",
    "assert os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"), \"Missing AZURE_OPENAI_DEPLOYMENT\"\n",
    "\n",
    "print(f\"‚úÖ Project root: {project_root}\")\n",
    "print(f\"‚úÖ Azure OpenAI endpoint: {os.getenv('AZURE_OPENAI_ENDPOINT')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecf3e9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Microsoft Agent Framework components imported!\n",
      "‚úÖ Azure OpenAI client created with deployment: gpt-4.1-mini\n"
     ]
    }
   ],
   "source": [
    "# Import Microsoft Agent Framework components\n",
    "import os\n",
    "import asyncio\n",
    "from typing import Any\n",
    "\n",
    "# Agent Framework imports\n",
    "from agent_framework import WorkflowBuilder, ChatAgent\n",
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "# Telemetry setup\n",
    "from src.common.telemetry import setup_telemetry, get_tracer\n",
    "setup_telemetry()\n",
    "tracer = get_tracer(__name__)\n",
    "\n",
    "# Create token provider for Azure OpenAI with correct scope\n",
    "credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(\n",
    "    credential, \n",
    "    \"https://cognitiveservices.azure.com/.default\"\n",
    ")\n",
    "\n",
    "# Create Azure OpenAI chat client with token provider\n",
    "# Note: The parameter is 'ad_token_provider' not 'azure_ad_token_provider'\n",
    "chat_client = AzureOpenAIChatClient(\n",
    "    ad_token_provider=token_provider,\n",
    "    endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    deployment_name=os.environ[\"AZURE_OPENAI_DEPLOYMENT\"],\n",
    "    api_version=os.environ.get(\"AZURE_OPENAI_VERSION\", \"2024-12-01-preview\"),\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Microsoft Agent Framework components imported!\")\n",
    "print(f\"‚úÖ Azure OpenAI client created with deployment: {os.environ['AZURE_OPENAI_DEPLOYMENT']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c03a0e",
   "metadata": {},
   "source": [
    "## Part 3: Basic Sequential Workflow\n",
    "\n",
    "Let's create a simple sequential workflow using `WorkflowBuilder` and `ChatAgent`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d881fa5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No outgoing edges found for executor step3_agent; dropping messages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step1_agent]: Hello, Workflow!\n",
      "[step1_agent]: [Step 1]: Hello, Workflow! How can I assist you today?\n",
      "[step1_agent]: [AgentExecutorResponse(executor_id='step1_agent', agent_run_response=<agent_framework._types.AgentRu...\n",
      "[step2_agent]: AgentExecutorResponse(executor_id='step1_agent', agent_run_response=<agent_framework._types.AgentRun...\n",
      "[step2_agent]: [Step 2]: Hello, Workflow! How can I assist you today?\n",
      "[step2_agent]: [AgentExecutorResponse(executor_id='step2_agent', agent_run_response=<agent_framework._types.AgentRu...\n",
      "[step3_agent]: AgentExecutorResponse(executor_id='step2_agent', agent_run_response=<agent_framework._types.AgentRun...\n",
      "[step3_agent]: [Step 3]: Hello, Workflow!\n",
      "[step3_agent]: [AgentExecutorResponse(executor_id='step3_agent', agent_run_response=<agent_framework._types.AgentRu...\n",
      "\n",
      "‚úÖ Workflow completed in 6017.08ms\n",
      "Final output: [AgentExecutorResponse(executor_id='step3_agent', agent_run_response=<agent_framework._types.AgentRunResponse object at 0x000002CF5D532510>, full_conversation=[<agent_framework._types.ChatMessage object at 0x000002CF5CD1EA50>, <agent_framework._types.ChatMessage object at 0x000002CF5D5311F0>, <agent_framework._types.ChatMessage object at 0x000002CF5D4A1E80>, <agent_framework._types.ChatMessage object at 0x000002CF5D530470>])]\n"
     ]
    }
   ],
   "source": [
    "# Create specialized agents for each step\n",
    "step1_agent = chat_client.create_agent(\n",
    "    name=\"step1_agent\",\n",
    "    instructions=\"You are Step 1. Add the prefix '[Step 1]:' to the beginning of any message you receive. Return ONLY the prefixed message, nothing else.\"\n",
    ")\n",
    "\n",
    "step2_agent = chat_client.create_agent(\n",
    "    name=\"step2_agent\",\n",
    "    instructions=\"You are Step 2. Add the prefix '[Step 2]:' to the beginning of any message you receive. Return ONLY the prefixed message, nothing else.\"\n",
    ")\n",
    "\n",
    "step3_agent = chat_client.create_agent(\n",
    "    name=\"step3_agent\",\n",
    "    instructions=\"You are Step 3. Add the prefix '[Step 3]:' to the beginning of any message you receive. Return ONLY the prefixed message, nothing else.\"\n",
    ")\n",
    "\n",
    "# Build workflow with sequential edges\n",
    "workflow = (\n",
    "    WorkflowBuilder()\n",
    "    .set_start_executor(step1_agent)\n",
    "    .add_edge(step1_agent, step2_agent)\n",
    "    .add_edge(step2_agent, step3_agent)\n",
    "    .build()\n",
    ")\n",
    "\n",
    "# Execute the workflow\n",
    "import time\n",
    "start = time.time()\n",
    "events = await workflow.run(\"Hello, Workflow!\")\n",
    "duration = (time.time() - start) * 1000\n",
    "\n",
    "# Collect results\n",
    "final_output = None\n",
    "for event in events:\n",
    "    # Only process events that have executor_id (agent events)\n",
    "    if hasattr(event, 'executor_id') and hasattr(event, 'data'):\n",
    "        executor_id = event.executor_id\n",
    "        data = event.data\n",
    "        # Handle AgentRunResponse objects\n",
    "        if hasattr(data, 'text'):\n",
    "            output_text = data.text\n",
    "        elif hasattr(data, 'messages') and data.messages:\n",
    "            # Get text from the last message\n",
    "            last_msg = data.messages[-1]\n",
    "            if hasattr(last_msg, 'content'):\n",
    "                output_text = str(last_msg.content)\n",
    "            else:\n",
    "                output_text = str(last_msg)\n",
    "        else:\n",
    "            output_text = str(data)\n",
    "        final_output = output_text\n",
    "        truncated = output_text[:100] + \"...\" if len(output_text) > 100 else output_text\n",
    "        print(f\"[{executor_id}]: {truncated}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Workflow completed in {duration:.2f}ms\")\n",
    "print(f\"Final output: {final_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c6816b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Streaming Workflow Execution ===\n",
      "\n",
      "üì§ [step1_agent]: Hello, Streaming Workflow!...\n",
      "üì§ [step1_agent]: ...\n",
      "üì§ [step1_agent]: [...\n",
      "üì§ [step1_agent]: Step...\n",
      "üì§ [step1_agent]:  ...\n",
      "üì§ [step1_agent]: 1...\n",
      "üì§ [step1_agent]: ]:...\n",
      "üì§ [step1_agent]:  Hello...\n",
      "üì§ [step1_agent]: ,...\n",
      "üì§ [step1_agent]:  Streaming...\n",
      "üì§ [step1_agent]:  Workflow...\n",
      "üì§ [step1_agent]: !...\n",
      "üì§ [step1_agent]:  How...\n",
      "üì§ [step1_agent]:  can...\n",
      "üì§ [step1_agent]:  I...\n",
      "üì§ [step1_agent]:  assist...\n",
      "üì§ [step1_agent]:  you...\n",
      "üì§ [step1_agent]:  today...\n",
      "üì§ [step1_agent]: ?...\n",
      "üì§ [step1_agent]: ...\n",
      "üì§ [step1_agent]: ...\n",
      "üì§ [step1_agent]: [AgentExecutorResponse(executor_id='step1_agent', agent_run_response=<agent_fram...\n",
      "üì§ [step2_agent]: AgentExecutorResponse(executor_id='step1_agent', agent_run_response=<agent_frame...\n",
      "üì§ [step2_agent]: ...\n",
      "üì§ [step2_agent]: [...\n",
      "üì§ [step2_agent]: Step...\n",
      "üì§ [step2_agent]:  ...\n",
      "üì§ [step2_agent]: 2...\n",
      "üì§ [step2_agent]: ]:...\n",
      "üì§ [step2_agent]:  Hello...\n",
      "üì§ [step2_agent]: ,...\n",
      "üì§ [step2_agent]:  Streaming...\n",
      "üì§ [step2_agent]:  Workflow...\n",
      "üì§ [step2_agent]: !...\n",
      "üì§ [step2_agent]:  How...\n",
      "üì§ [step2_agent]:  can...\n",
      "üì§ [step2_agent]:  I...\n",
      "üì§ [step2_agent]:  assist...\n",
      "üì§ [step2_agent]:  you...\n",
      "üì§ [step2_agent]:  today...\n",
      "üì§ [step2_agent]: ?...\n",
      "üì§ [step2_agent]: ...\n",
      "üì§ [step2_agent]: ...\n",
      "üì§ [step2_agent]: [AgentExecutorResponse(executor_id='step2_agent', agent_run_response=<agent_fram...\n",
      "üì§ [step3_agent]: AgentExecutorResponse(executor_id='step2_agent', agent_run_response=<agent_frame...\n",
      "üì§ [step3_agent]: ...\n",
      "üì§ [step3_agent]: [...\n",
      "üì§ [step3_agent]: Step...\n",
      "üì§ [step3_agent]:  ...\n",
      "üì§ [step3_agent]: 3...\n",
      "üì§ [step3_agent]: ]:...\n",
      "üì§ [step3_agent]:  Hello...\n",
      "üì§ [step3_agent]: ,...\n",
      "üì§ [step3_agent]:  Streaming...\n",
      "üì§ [step3_agent]:  Workflow...\n",
      "üì§ [step3_agent]: !...\n",
      "üì§ [step3_agent]: ...\n",
      "üì§ [step3_agent]: ...\n",
      "üì§ [step3_agent]: [AgentExecutorResponse(executor_id='step3_agent', agent_run_response=<agent_fram...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No outgoing edges found for executor step3_agent; dropping messages.\n"
     ]
    }
   ],
   "source": [
    "# Stream workflow events in real-time\n",
    "print(\"=== Streaming Workflow Execution ===\\n\")\n",
    "\n",
    "async for event in workflow.run_stream(\"Hello, Streaming Workflow!\"):\n",
    "    if hasattr(event, 'executor_id') and hasattr(event, 'data'):\n",
    "        data = event.data\n",
    "        # Handle AgentRunResponseUpdate objects\n",
    "        if hasattr(data, 'text'):\n",
    "            output_text = data.text\n",
    "        elif hasattr(data, 'delta') and data.delta:\n",
    "            output_text = str(data.delta)\n",
    "        else:\n",
    "            output_text = str(data)[:80]\n",
    "        print(f\"üì§ [{event.executor_id}]: {output_text}...\")\n",
    "    elif hasattr(event, 'type'):\n",
    "        print(f\"üìç Event: {event.type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6fa91e",
   "metadata": {},
   "source": [
    "## Part 4: Chained Agent Pipelines\n",
    "\n",
    "Create more complex pipelines by chaining multiple agents with `add_edge()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01c6bfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 'hello world'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No outgoing edges found for executor count; dropping messages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 'None'\n",
      "\n",
      "Note: Each agent in the chain processes the output of the previous agent.\n"
     ]
    }
   ],
   "source": [
    "# Create a text processing pipeline with specialized agents\n",
    "\n",
    "uppercase_agent = chat_client.create_agent(\n",
    "    name=\"uppercase\",\n",
    "    instructions=\"Convert the input text to UPPERCASE. Return ONLY the uppercase text.\"\n",
    ")\n",
    "\n",
    "reverse_agent = chat_client.create_agent(\n",
    "    name=\"reverse\",\n",
    "    instructions=\"Reverse the order of characters in the input text. Return ONLY the reversed text.\"\n",
    ")\n",
    "\n",
    "count_agent = chat_client.create_agent(\n",
    "    name=\"count\",\n",
    "    instructions=\"Count the characters in the input and append ' (length: N)' to the text. Return the text with the count.\"\n",
    ")\n",
    "\n",
    "# Build text processing pipeline\n",
    "text_pipeline = (\n",
    "    WorkflowBuilder()\n",
    "    .set_start_executor(uppercase_agent)\n",
    "    .add_edge(uppercase_agent, reverse_agent)\n",
    "    .add_edge(reverse_agent, count_agent)\n",
    "    .build()\n",
    ")\n",
    "\n",
    "# Execute pipeline\n",
    "input_text = \"hello world\"\n",
    "print(f\"Input: '{input_text}'\")\n",
    "\n",
    "events = await text_pipeline.run(input_text)\n",
    "\n",
    "final_result = None\n",
    "for event in events:\n",
    "    if hasattr(event, 'data'):\n",
    "        final_result = event.data\n",
    "\n",
    "print(f\"Output: '{final_result}'\")\n",
    "print(\"\\nNote: Each agent in the chain processes the output of the previous agent.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a46748",
   "metadata": {},
   "source": [
    "## Part 5: Parallel Execution with asyncio.gather()\n",
    "\n",
    "Execute multiple agents concurrently when their operations are independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "708eaffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è±Ô∏è Duration: 1703.67ms (parallel execution!)\n",
      "\n",
      "üìä Sentiment: {\"sentiment\": \"neutral\", \"confidence\": 0.85}...\n",
      "\n",
      "üè∑Ô∏è Entities: {\n",
      "  \"entities\": [\n",
      "    {\"text\": \"Apple\", \"type\": \"ORG\"},\n",
      "    {\"text\": \"Tim Cook\", \"type\": \"PERSON\"},\n",
      "...\n",
      "\n",
      "üìë Topics: {\"topics\": [\"Apple\", \"Tim Cook\", \"iPhone announcement\", \"Cupertino\", \"Apple headquarters\"]}...\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "# Create parallel analysis agents\n",
    "sentiment_agent = chat_client.create_agent(\n",
    "    name=\"sentiment\",\n",
    "    instructions=\"Analyze the sentiment of the input text. Return a JSON object with: {\\\"sentiment\\\": \\\"positive|negative|neutral\\\", \\\"confidence\\\": 0.0-1.0}\"\n",
    ")\n",
    "\n",
    "entities_agent = chat_client.create_agent(\n",
    "    name=\"entities\",\n",
    "    instructions=\"Extract named entities from the input text. Return a JSON object with: {\\\"entities\\\": [{\\\"text\\\": \\\"...\\\", \\\"type\\\": \\\"PERSON|ORG|LOCATION\\\"}]}\"\n",
    ")\n",
    "\n",
    "topics_agent = chat_client.create_agent(\n",
    "    name=\"topics\",\n",
    "    instructions=\"Identify the main topics in the input text. Return a JSON object with: {\\\"topics\\\": [\\\"topic1\\\", \\\"topic2\\\", ...]}\"\n",
    ")\n",
    "\n",
    "def get_response_text(response) -> str:\n",
    "    \"\"\"Extract text from AgentRunResponse.\"\"\"\n",
    "    if hasattr(response, 'text') and response.text:\n",
    "        return response.text\n",
    "    if hasattr(response, 'messages') and response.messages:\n",
    "        last_msg = response.messages[-1]\n",
    "        if hasattr(last_msg, 'content'):\n",
    "            return str(last_msg.content)\n",
    "    return str(response)\n",
    "\n",
    "async def parallel_analysis(text: str) -> dict:\n",
    "    \"\"\"Execute multiple agents in parallel using asyncio.gather().\"\"\"\n",
    "    start = time.time()\n",
    "    \n",
    "    # Run all agents concurrently\n",
    "    results = await asyncio.gather(\n",
    "        sentiment_agent.run(text),\n",
    "        entities_agent.run(text),\n",
    "        topics_agent.run(text),\n",
    "    )\n",
    "    \n",
    "    duration = (time.time() - start) * 1000\n",
    "    \n",
    "    return {\n",
    "        \"sentiment\": get_response_text(results[0]),\n",
    "        \"entities\": get_response_text(results[1]),\n",
    "        \"topics\": get_response_text(results[2]),\n",
    "        \"duration_ms\": duration,\n",
    "    }\n",
    "\n",
    "# Test parallel execution\n",
    "sample_text = \"Apple CEO Tim Cook announced the new iPhone at the company's headquarters in Cupertino, California.\"\n",
    "\n",
    "result = await parallel_analysis(sample_text)\n",
    "\n",
    "print(f\"‚è±Ô∏è Duration: {result['duration_ms']:.2f}ms (parallel execution!)\")\n",
    "print(f\"\\nüìä Sentiment: {result['sentiment'][:100]}...\")\n",
    "print(f\"\\nüè∑Ô∏è Entities: {result['entities'][:100]}...\")\n",
    "print(f\"\\nüìë Topics: {result['topics'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2760f0d",
   "metadata": {},
   "source": [
    "## Part 6: Conditional Branching with add_edge(condition=...)\n",
    "\n",
    "Route to different agents based on runtime conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "722b0acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short text (30 chars): 'AI is transforming industries.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No outgoing edges found for executor expand; dropping messages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[router]: AI is transforming industries....\n",
      "[router]: SHORT...\n",
      "[router]: [AgentExecutorResponse(executor_id='router', agent_run_response=<agent_framework._types.AgentRunResponse object at 0x000002CF5CD1E9F0>, full_conversat...\n",
      "[expand]: SHORT...\n",
      "[expand]: Artificial intelligence (AI) is revolutionizing various industries by automating tasks, enhancing decision-making, and improving efficiency. In sector...\n",
      "[expand]: [AgentExecutorResponse(executor_id='expand', agent_run_response=<agent_framework._types.AgentRunResponse object at 0x000002CF5D4FDC40>, full_conversat...\n",
      "\n",
      "Long text (285 chars): 'Artificial intelligence has been making remarkable...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No outgoing edges found for executor summarize; dropping messages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[router]: Artificial intelligence has been making remarkable strides in recent years, with applications spanning healthcare, finance, transportation, and entert...\n",
      "[router]: LONG...\n",
      "[router]: [AgentExecutorResponse(executor_id='router', agent_run_response=<agent_framework._types.AgentRunResponse object at 0x000002CF5E5B7020>, full_conversat...\n",
      "[summarize]: LONG...\n",
      "[summarize]: Artificial intelligence has advanced significantly, impacting various fields such as healthcare, finance, transportation, and entertainment. Machine l...\n",
      "[summarize]: [AgentExecutorResponse(executor_id='summarize', agent_run_response=<agent_framework._types.AgentRunResponse object at 0x000002CF5D532480>, full_conver...\n"
     ]
    }
   ],
   "source": [
    "# Create router and specialized agents\n",
    "router_agent = chat_client.create_agent(\n",
    "    name=\"router\",\n",
    "    instructions=\"Determine if the input text is long (>100 chars) or short. Return exactly 'LONG' or 'SHORT'.\"\n",
    ")\n",
    "\n",
    "summarize_agent = chat_client.create_agent(\n",
    "    name=\"summarize\",\n",
    "    instructions=\"Summarize the long text into 2-3 sentences. Be concise.\"\n",
    ")\n",
    "\n",
    "expand_agent = chat_client.create_agent(\n",
    "    name=\"expand\",\n",
    "    instructions=\"Expand the short text into a more detailed explanation (3-4 sentences).\"\n",
    ")\n",
    "\n",
    "def extract_text_from_response(data) -> str:\n",
    "    \"\"\"Extract text from AgentExecutorResponse or string.\"\"\"\n",
    "    if isinstance(data, str):\n",
    "        return data\n",
    "    if hasattr(data, 'agent_run_response'):\n",
    "        response = data.agent_run_response\n",
    "        if hasattr(response, 'text') and response.text:\n",
    "            return response.text\n",
    "        if hasattr(response, 'messages') and response.messages:\n",
    "            last_msg = response.messages[-1]\n",
    "            if hasattr(last_msg, 'content'):\n",
    "                return str(last_msg.content)\n",
    "    return str(data)\n",
    "\n",
    "# Define condition functions that work with AgentExecutorResponse\n",
    "def is_long_text(data) -> bool:\n",
    "    \"\"\"Check if router response indicates LONG.\"\"\"\n",
    "    text = extract_text_from_response(data)\n",
    "    return \"LONG\" in text.upper()\n",
    "\n",
    "def is_short_text(data) -> bool:\n",
    "    \"\"\"Check if router response indicates SHORT.\"\"\"\n",
    "    text = extract_text_from_response(data)\n",
    "    return \"SHORT\" in text.upper()\n",
    "\n",
    "# Build conditional workflow\n",
    "conditional_workflow = (\n",
    "    WorkflowBuilder()\n",
    "    .set_start_executor(router_agent)\n",
    "    .add_edge(router_agent, summarize_agent, condition=is_long_text)\n",
    "    .add_edge(router_agent, expand_agent, condition=is_short_text)\n",
    "    .build()\n",
    ")\n",
    "\n",
    "# Test with short text\n",
    "short_text = \"AI is transforming industries.\"\n",
    "print(f\"Short text ({len(short_text)} chars): '{short_text}'\")\n",
    "events = await conditional_workflow.run(short_text)\n",
    "for event in events:\n",
    "    if hasattr(event, 'executor_id') and hasattr(event, 'data'):\n",
    "        text = extract_text_from_response(event.data)\n",
    "        print(f\"[{event.executor_id}]: {text[:150]}...\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Test with long text\n",
    "long_text = \"Artificial intelligence has been making remarkable strides in recent years, with applications spanning healthcare, finance, transportation, and entertainment. Machine learning algorithms are now capable of diagnosing diseases, predicting market trends, and driving autonomous vehicles.\"\n",
    "print(f\"Long text ({len(long_text)} chars): '{long_text[:50]}...'\")\n",
    "events = await conditional_workflow.run(long_text)\n",
    "for event in events:\n",
    "    if hasattr(event, 'executor_id') and hasattr(event, 'data'):\n",
    "        text = extract_text_from_response(event.data)\n",
    "        print(f\"[{event.executor_id}]: {text[:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7013b87e",
   "metadata": {},
   "source": [
    "## Part 7: Data Transformation Between Agents\n",
    "\n",
    "Pass structured data between agents using prompt templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67ec02ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: The artificial intelligence revolution is transfor...\n",
      "Keywords: ['artificial intelligence', 'machine learning', 'deep neural networks', 'revolution', 'industries']\n",
      "Count: 5\n"
     ]
    }
   ],
   "source": [
    "# Data transformation through prompt templates\n",
    "\n",
    "keyword_extractor = chat_client.create_agent(\n",
    "    name=\"keyword_extractor\",\n",
    "    instructions=\"\"\"Extract the top 5 keywords from the input text.\n",
    "Return ONLY a comma-separated list of keywords, nothing else.\n",
    "Example: keyword1, keyword2, keyword3, keyword4, keyword5\"\"\"\n",
    ")\n",
    "\n",
    "def get_text_from_run_response(response) -> str:\n",
    "    \"\"\"Extract text from AgentRunResponse.\"\"\"\n",
    "    if hasattr(response, 'text') and response.text:\n",
    "        return response.text\n",
    "    if hasattr(response, 'messages') and response.messages:\n",
    "        last_msg = response.messages[-1]\n",
    "        if hasattr(last_msg, 'content'):\n",
    "            return str(last_msg.content)\n",
    "    return str(response)\n",
    "\n",
    "async def extract_and_transform(text: str) -> dict:\n",
    "    \"\"\"Extract keywords and return structured data.\"\"\"\n",
    "    # Run keyword extraction\n",
    "    result = await keyword_extractor.run(text)\n",
    "    \n",
    "    # Transform response to structured format\n",
    "    result_text = get_text_from_run_response(result)\n",
    "    keywords = [k.strip() for k in result_text.split(',')]\n",
    "    \n",
    "    return {\n",
    "        \"original_text\": text[:50] + \"...\",\n",
    "        \"keywords\": keywords[:5],\n",
    "        \"keyword_count\": len(keywords),\n",
    "    }\n",
    "\n",
    "# Test data transformation\n",
    "sample = \"The artificial intelligence revolution is transforming industries worldwide through machine learning and deep neural networks.\"\n",
    "\n",
    "result = await extract_and_transform(sample)\n",
    "\n",
    "print(f\"Original: {result['original_text']}\")\n",
    "print(f\"Keywords: {result['keywords']}\")\n",
    "print(f\"Count: {result['keyword_count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f0ceca",
   "metadata": {},
   "source": [
    "## Part 8: Error Handling with Middleware\n",
    "\n",
    "Use middleware patterns for retry logic and error handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f23ab915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Middleware patterns defined\n"
     ]
    }
   ],
   "source": [
    "# Define a retry middleware for agent calls\n",
    "import asyncio\n",
    "from typing import Callable, Any\n",
    "\n",
    "class RetryMiddleware:\n",
    "    \"\"\"Middleware that retries failed agent calls with exponential backoff.\"\"\"\n",
    "    \n",
    "    def __init__(self, max_retries: int = 3, base_delay: float = 1.0, max_delay: float = 10.0):\n",
    "        self.max_retries = max_retries\n",
    "        self.base_delay = base_delay\n",
    "        self.max_delay = max_delay\n",
    "    \n",
    "    async def execute(self, func: Callable, *args, **kwargs) -> Any:\n",
    "        \"\"\"Execute function with retry logic.\"\"\"\n",
    "        delay = self.base_delay\n",
    "        last_error = None\n",
    "        \n",
    "        for attempt in range(self.max_retries + 1):\n",
    "            try:\n",
    "                return await func(*args, **kwargs)\n",
    "            except Exception as e:\n",
    "                last_error = e\n",
    "                if attempt < self.max_retries:\n",
    "                    print(f\"‚ö†Ô∏è Attempt {attempt + 1} failed: {e}\")\n",
    "                    print(f\"   Retrying in {delay:.1f}s...\")\n",
    "                    await asyncio.sleep(delay)\n",
    "                    delay = min(delay * 2, self.max_delay)\n",
    "        \n",
    "        raise last_error\n",
    "\n",
    "# Example: Safe workflow wrapper with error handling\n",
    "async def safe_agent_call(agent, prompt: str, fallback: str = \"Unable to process request.\"):\n",
    "    \"\"\"Execute agent with fallback on failure.\"\"\"\n",
    "    try:\n",
    "        return await agent.run(prompt)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Agent call failed: {e}\")\n",
    "        return fallback\n",
    "\n",
    "print(\"‚úÖ Middleware patterns defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f71545c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords: product, launch, huge, success,...\n",
      "Sentiment: {\"sentiment\": \"positive\", \"confidence\": 0.95}...\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate safe workflow execution with error handling\n",
    "\n",
    "async def robust_workflow(text: str) -> dict:\n",
    "    \"\"\"Execute a workflow with comprehensive error handling.\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Step 1: Extract keywords with fallback\n",
    "    keyword_result = await safe_agent_call(\n",
    "        keyword_extractor,\n",
    "        text,\n",
    "        fallback=\"keyword extraction failed\"\n",
    "    )\n",
    "    results[\"keywords\"] = get_text_from_run_response(keyword_result) if hasattr(keyword_result, 'messages') else keyword_result\n",
    "    \n",
    "    # Step 2: Analyze sentiment with fallback\n",
    "    sentiment_result = await safe_agent_call(\n",
    "        sentiment_agent,\n",
    "        text,\n",
    "        fallback='{\"sentiment\": \"unknown\", \"confidence\": 0.0}'\n",
    "    )\n",
    "    results[\"sentiment\"] = get_text_from_run_response(sentiment_result) if hasattr(sentiment_result, 'messages') else sentiment_result\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test robust workflow\n",
    "result = await robust_workflow(\"The product launch was a huge success!\")\n",
    "print(f\"Keywords: {result['keywords'][:80]}...\")\n",
    "print(f\"Sentiment: {result['sentiment'][:80]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "868b84f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Circuit breaker initialized (state: CLOSED)\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate circuit breaker pattern for resilience\n",
    "\n",
    "class CircuitBreaker:\n",
    "    \"\"\"Simple circuit breaker to prevent cascading failures.\"\"\"\n",
    "    \n",
    "    def __init__(self, failure_threshold: int = 3, reset_timeout: float = 30.0):\n",
    "        self.failure_threshold = failure_threshold\n",
    "        self.reset_timeout = reset_timeout\n",
    "        self.failures = 0\n",
    "        self.last_failure_time = None\n",
    "        self.state = \"CLOSED\"  # CLOSED, OPEN, HALF_OPEN\n",
    "    \n",
    "    def can_execute(self) -> bool:\n",
    "        \"\"\"Check if execution is allowed.\"\"\"\n",
    "        if self.state == \"CLOSED\":\n",
    "            return True\n",
    "        \n",
    "        if self.state == \"OPEN\":\n",
    "            import time\n",
    "            if time.time() - self.last_failure_time > self.reset_timeout:\n",
    "                self.state = \"HALF_OPEN\"\n",
    "                return True\n",
    "            return False\n",
    "        \n",
    "        return True  # HALF_OPEN allows one attempt\n",
    "    \n",
    "    def record_success(self):\n",
    "        \"\"\"Record successful execution.\"\"\"\n",
    "        self.failures = 0\n",
    "        self.state = \"CLOSED\"\n",
    "    \n",
    "    def record_failure(self):\n",
    "        \"\"\"Record failed execution.\"\"\"\n",
    "        import time\n",
    "        self.failures += 1\n",
    "        self.last_failure_time = time.time()\n",
    "        \n",
    "        if self.failures >= self.failure_threshold:\n",
    "            self.state = \"OPEN\"\n",
    "            print(f\"üî¥ Circuit breaker OPEN (failures: {self.failures})\")\n",
    "\n",
    "circuit_breaker = CircuitBreaker()\n",
    "print(f\"‚úÖ Circuit breaker initialized (state: {circuit_breaker.state})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7baf4d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: success\n",
      "Result: {\"sentiment\": \"positive\", \"confidence\": 0.95}...\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate timeout handling for agent calls\n",
    "\n",
    "def extract_text(response) -> str:\n",
    "    \"\"\"Extract text from AgentRunResponse or return string.\"\"\"\n",
    "    if isinstance(response, str):\n",
    "        return response\n",
    "    if hasattr(response, 'text') and response.text:\n",
    "        return response.text\n",
    "    if hasattr(response, 'messages') and response.messages:\n",
    "        last_msg = response.messages[-1]\n",
    "        if hasattr(last_msg, 'content'):\n",
    "            return str(last_msg.content)\n",
    "    return str(response)\n",
    "\n",
    "async def agent_with_timeout(agent, prompt: str, timeout_seconds: float = 30.0):\n",
    "    \"\"\"Execute agent with timeout.\"\"\"\n",
    "    try:\n",
    "        result = await asyncio.wait_for(\n",
    "            agent.run(prompt),\n",
    "            timeout=timeout_seconds\n",
    "        )\n",
    "        return {\"status\": \"success\", \"result\": extract_text(result)}\n",
    "    except asyncio.TimeoutError:\n",
    "        return {\"status\": \"timeout\", \"result\": f\"Agent timed out after {timeout_seconds}s\"}\n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"result\": str(e)}\n",
    "\n",
    "# Test timeout handling\n",
    "result = await agent_with_timeout(\n",
    "    sentiment_agent,\n",
    "    \"This is a great day!\",\n",
    "    timeout_seconds=30.0\n",
    ")\n",
    "\n",
    "print(f\"Status: {result['status']}\")\n",
    "print(f\"Result: {result['result'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6cba39",
   "metadata": {},
   "source": [
    "## Part 9: Retry Strategies with Middleware\n",
    "\n",
    "The Agent Framework uses middleware patterns for cross-cutting concerns like retries. We've implemented a `RetryMiddleware` that can be composed with any agent call.\n",
    "\n",
    "Key benefits:\n",
    "- **Composable**: Wrap any agent call with retry behavior\n",
    "- **Configurable**: Customize retry counts, delays, and conditions\n",
    "- **Transparent**: The underlying agent code doesn't need to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25c41c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Attempt 1 failed: Simulated failure on call #1\n",
      "   Retrying in 0.1s...\n",
      "‚ö†Ô∏è Attempt 2 failed: Simulated failure on call #2\n",
      "   Retrying in 0.2s...\n",
      "‚ö†Ô∏è Attempt 3 failed: Simulated failure on call #3\n",
      "   Retrying in 0.4s...\n",
      "‚ö†Ô∏è Attempt 4 failed: Simulated failure on call #4\n",
      "   Retrying in 0.8s...\n",
      "‚ö†Ô∏è Attempt 5 failed: Simulated failure on call #5\n",
      "   Retrying in 1.0s...\n",
      "‚úì Success on call #6: Processed 'Please analyze this important ...'\n",
      "Total API calls: 6\n"
     ]
    }
   ],
   "source": [
    "# Simulate a flaky operation and test retry middleware\n",
    "\n",
    "import random\n",
    "\n",
    "class FlakyAgent:\n",
    "    \"\"\"Agent that randomly fails to demonstrate retry patterns.\"\"\"\n",
    "    \n",
    "    def __init__(self, failure_rate: float = 0.7):\n",
    "        self.failure_rate = failure_rate\n",
    "        self.call_count = 0\n",
    "    \n",
    "    async def run(self, prompt: str) -> str:\n",
    "        self.call_count += 1\n",
    "        if random.random() < self.failure_rate:\n",
    "            raise Exception(f\"Simulated failure on call #{self.call_count}\")\n",
    "        return f\"Success on call #{self.call_count}: Processed '{prompt[:30]}...'\"\n",
    "\n",
    "# Create flaky agent and retry middleware\n",
    "flaky_agent = FlakyAgent(failure_rate=0.7)\n",
    "retry_middleware = RetryMiddleware(max_retries=5, base_delay=0.1, max_delay=1.0)\n",
    "\n",
    "# Execute with retry\n",
    "async def run_with_retry():\n",
    "    return await retry_middleware.execute(\n",
    "        flaky_agent.run,\n",
    "        \"Please analyze this important data\"\n",
    "    )\n",
    "\n",
    "try:\n",
    "    result = await run_with_retry()\n",
    "    print(f\"‚úì {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚úó Failed after all retries: {e}\")\n",
    "\n",
    "print(f\"Total API calls: {flaky_agent.call_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea3edda",
   "metadata": {},
   "source": [
    "## Part 10: The Framework's WorkflowBuilder Pattern\n",
    "\n",
    "The Microsoft Agent Framework provides a `WorkflowBuilder` class that enables declarative workflow construction. Here's the complete pattern for building complex workflows:\n",
    "\n",
    "```python\n",
    "# The canonical pattern for Agent Framework workflows:\n",
    "workflow = (\n",
    "    WorkflowBuilder()\n",
    "    .set_start_executor(agent_1)\n",
    "    .add_edge(agent_1, agent_2)\n",
    "    .add_edge(agent_2, agent_3, condition=some_condition)\n",
    "    .build()\n",
    ")\n",
    "```\n",
    "\n",
    "**Key Components**:\n",
    "- `set_start_executor()`: Define the entry point\n",
    "- `add_edge()`: Create connections between agents\n",
    "- `condition=`: Add conditional routing\n",
    "- `build()`: Finalize the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "474abf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Complete Analysis Workflow ===\n",
      "\n",
      "Input Text:\n",
      "\n",
      "Q3 2024 Results: Revenue increased 15% YoY to $2.4B.\n",
      "Operating margin improved to 28%. Cloud services grew 45%.\n",
      "New customer acquisition up 22% with 95% retention rate.\n",
      "\n",
      "\n",
      "1. Extraction:\n",
      "- Quarter: Q3 2024  \n",
      "- Revenue: $2.4 billion (15% year-over-year increase)  \n",
      "- Operating margin: 28%  \n",
      "- Cloud services growth: 45%  \n",
      "- New customer acquisition: 22% increase  \n",
      "- Customer retention rate: 95%\n",
      "\n",
      "2. Analysis:\n",
      "Based on the extracted facts about the company's Q3 2024 performance, several insights and patterns emerge:\n",
      "\n",
      "1. **Strong Overall Revenue Growth**  \n",
      "   - The company reported $2.4 billion in revenue, a 15% increase compared to the same quarter last year.  \n",
      "   - This indicates solid market demand and effective sales strategies.\n",
      "\n",
      "2. **High Operating Margin Indicates Efficient Operations**  \n",
      "   - An operating margin of 28% is relatively high, suggesting the company manages costs well and maintains strong profitability.  \n",
      "   - This margin supports potential reinvestment in growth initiatives or healthy returns to shareholders.\n",
      "\n",
      "3. **Cloud Services Are a Major Growth Driver**  \n",
      "   - Cloud services grew by 45%, significantly outpacing overall revenue growth.  \n",
      "   - This implies cloud offerings are a key strategic focus and are gaining market traction rapidly.  \n",
      "   - Cloud likely contributes disproportionately to total revenue growth, possibly reshaping the company's revenue mix.\n",
      "\n",
      "4. **Effective Sales and Marketing Evidenced by New Customer Acquisition**  \n",
      "   - A 22% increase in new customers shows success in expanding the client base.  \n",
      "   - Coupled with strong revenue growth, this points to effective product-market fit and competitive positioning.\n",
      "\n",
      "5. **High Customer Retention Rate Suggests Strong Customer Loyalty**  \n",
      "   - A 95% retention rate indicates customers are generally satisfied and continuing their engagement.  \n",
      "   - This high retention helps stabilize revenue streams and lowers churn risk, which is critical for subscription or service-based models.\n",
      "\n",
      "### Conclusions and Implications  \n",
      "- The company is experiencing robust growth across multiple dimensions: revenue, customer acquisition, and cloud services.  \n",
      "- Cloud services growth outpaces overall revenue significantly, marking it as a strategic area for continued investment and focus.  \n",
      "- High operating margins combined with expanding customer base and retention demonstrate both operational efficiency and strong market appeal.  \n",
      "- Maintaining or enhancing customer satisfaction will be important to sustain the high retention rate.  \n",
      "- Future growth strategies should likely capitalize on cloud services momentum while leveraging the strong customer foundation.\n",
      "\n",
      "Overall, the company appears to be in a healthy growth phase with strong profitability and expanding market presence, especially in cloud-related offerings.\n",
      "\n",
      "3. Final Output:\n",
      "**Q3 2024 Company Performance Analysis**\n",
      "\n",
      "**1. Strong Overall Revenue Growth**  \n",
      "- The company reported revenue of $2.4 billion, reflecting a 15% increase compared to Q3 2023.  \n",
      "- This growth signals robust market demand and effective sales strategies driving top-line performance.\n",
      "\n",
      "**2. High Operating Margin Indicates Efficient Operations**  \n",
      "- An operating margin of 28% denotes strong cost management and profitability.  \n",
      "- Such efficiency enables reinvestment into growth initiatives and supports healthy returns to shareholders.\n",
      "\n",
      "**3. Cloud Services as a Key Growth Driver**  \n",
      "- Cloud service revenues surged by 45%, significantly outpacing overall revenue growth.  \n",
      "- This rapid expansion underscores cloud offerings as a strategic focus with growing market traction.  \n",
      "- The contribution of cloud services is likely reshaping the company‚Äôs revenue mix and driving disproportionate growth.\n",
      "\n",
      "**4. Effective Sales and Marketing Reflected in New Customer Acquisition**  \n",
      "- New customers increased by 22%, indicating success in expanding the client base.  \n",
      "- This growth, alongside revenue gains, highlights a strong product-market fit and competitive positioning.\n",
      "\n",
      "**5. High Customer Retention Reflects Strong Loyalty**  \n",
      "- The customer retention rate stands at 95%, demonstrating sustained customer satisfaction and engagement.  \n",
      "- High retention stabilizes revenue streams and reduces churn risk, a vital factor for subscription- or service-based business models.\n",
      "\n",
      "---\n",
      "\n",
      "### Conclusions and Implications\n",
      "\n",
      "- The company is experiencing robust growth across revenue, customer acquisition, and cloud services segments.  \n",
      "- Cloud services growth substantially outpaces overall revenue, underscoring its importance as a strategic growth area.  \n",
      "- High operating margins combined with expanding and loyal customer bases indicate operational efficiency coupled with solid market appeal.  \n",
      "- Sustaining or improving customer satisfaction is critical to maintaining the high retention rate.  \n",
      "- Future growth strategies should leverage the momentum in cloud services while building upon the strong customer foundation.\n",
      "\n",
      "**Summary:**  \n",
      "Overall, the company is in a healthy growth phase characterized by strong profitability and an expanding market presence, particularly within cloud-related offerings.\n"
     ]
    }
   ],
   "source": [
    "# Build a complete analysis workflow using WorkflowBuilder\n",
    "\n",
    "# Create specialized agents for different analysis tasks\n",
    "extract_agent = chat_client.create_agent(\n",
    "    name=\"Extractor\",\n",
    "    instructions=\"You are a data extraction specialist. Extract key facts from text.\"\n",
    ")\n",
    "\n",
    "analyze_agent = chat_client.create_agent(\n",
    "    name=\"Analyzer\", \n",
    "    instructions=\"You are an analytical AI. Analyze patterns and draw conclusions.\"\n",
    ")\n",
    "\n",
    "format_agent = chat_client.create_agent(\n",
    "    name=\"Formatter\",\n",
    "    instructions=\"You are a formatting specialist. Format analysis results professionally.\"\n",
    ")\n",
    "\n",
    "# Build workflow with chained agents\n",
    "analysis_workflow = (\n",
    "    WorkflowBuilder()\n",
    "    .set_start_executor(extract_agent)\n",
    "    .add_edge(extract_agent, analyze_agent)\n",
    "    .add_edge(analyze_agent, format_agent)\n",
    "    .build()\n",
    ")\n",
    "\n",
    "# Execute the workflow\n",
    "sample_text = \"\"\"\n",
    "Q3 2024 Results: Revenue increased 15% YoY to $2.4B.\n",
    "Operating margin improved to 28%. Cloud services grew 45%.\n",
    "New customer acquisition up 22% with 95% retention rate.\n",
    "\"\"\"\n",
    "\n",
    "print(\"=== Complete Analysis Workflow ===\\n\")\n",
    "print(f\"Input Text:\\n{sample_text}\\n\")\n",
    "\n",
    "# Run extraction\n",
    "extract_result = await extract_agent.run(f\"Extract key metrics from: {sample_text}\")\n",
    "print(f\"1. Extraction:\\n{extract_result}\\n\")\n",
    "\n",
    "# Run analysis\n",
    "analyze_result = await analyze_agent.run(f\"Analyze these extracted facts: {extract_result}\")\n",
    "print(f\"2. Analysis:\\n{analyze_result}\\n\")\n",
    "\n",
    "# Run formatting\n",
    "format_result = await format_agent.run(f\"Format this analysis professionally: {analyze_result}\")\n",
    "print(f\"3. Final Output:\\n{format_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0245b31",
   "metadata": {},
   "source": [
    "## Part 11: Workflow Validation and Testing\n",
    "\n",
    "When building deterministic workflows, validation is critical:\n",
    "\n",
    "1. **Pre-execution validation**: Check all agents are properly configured\n",
    "2. **Runtime monitoring**: Track execution through each step\n",
    "3. **Post-execution validation**: Verify outputs meet expectations\n",
    "\n",
    "The Agent Framework's approach makes testing easier because each component is independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4947a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Workflow Validation ===\n",
      "\n",
      "Overall: ‚úì PASS\n",
      "Summary: 6/6 agents valid\n",
      "\n",
      "  ‚úì sentiment: OK\n",
      "  ‚úì entities: OK\n",
      "  ‚úì topics: OK\n",
      "  ‚úì Extractor: OK\n",
      "  ‚úì Analyzer: OK\n",
      "  ‚úì Formatter: OK\n"
     ]
    }
   ],
   "source": [
    "# Workflow validation utilities\n",
    "\n",
    "def validate_agent(agent) -> dict:\n",
    "    \"\"\"Validate agent configuration before workflow execution.\"\"\"\n",
    "    issues = []\n",
    "    agent_name = getattr(agent, 'name', 'Unknown')\n",
    "    \n",
    "    # Check required attributes\n",
    "    if not agent_name or agent_name == 'Unknown':\n",
    "        issues.append(\"Agent missing name\")\n",
    "    \n",
    "    # Check if agent has run method\n",
    "    if not hasattr(agent, 'run') or not callable(getattr(agent, 'run', None)):\n",
    "        issues.append(\"Agent missing run() method\")\n",
    "    \n",
    "    return {\n",
    "        \"agent\": agent_name,\n",
    "        \"valid\": len(issues) == 0,\n",
    "        \"issues\": issues\n",
    "    }\n",
    "\n",
    "def validate_workflow_agents(*agents) -> dict:\n",
    "    \"\"\"Validate all agents in a workflow.\"\"\"\n",
    "    results = [validate_agent(a) for a in agents]\n",
    "    all_valid = all(r[\"valid\"] for r in results)\n",
    "    \n",
    "    return {\n",
    "        \"valid\": all_valid,\n",
    "        \"agent_results\": results,\n",
    "        \"summary\": f\"{sum(1 for r in results if r['valid'])}/{len(results)} agents valid\"\n",
    "    }\n",
    "\n",
    "# Validate our workflow agents\n",
    "validation = validate_workflow_agents(\n",
    "    sentiment_agent,\n",
    "    entities_agent,\n",
    "    topics_agent,\n",
    "    extract_agent,\n",
    "    analyze_agent,\n",
    "    format_agent\n",
    ")\n",
    "\n",
    "print(\"=== Workflow Validation ===\\n\")\n",
    "print(f\"Overall: {'‚úì PASS' if validation['valid'] else '‚úó FAIL'}\")\n",
    "print(f\"Summary: {validation['summary']}\\n\")\n",
    "\n",
    "for result in validation['agent_results']:\n",
    "    status = \"‚úì\" if result['valid'] else \"‚úó\"\n",
    "    print(f\"  {status} {result['agent']}: {'OK' if result['valid'] else result['issues']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe21835",
   "metadata": {},
   "source": [
    "## Part 12: Hands-on Exercise\n",
    "\n",
    "**Challenge**: Build a content moderation workflow using the patterns learned.\n",
    "\n",
    "Your workflow should:\n",
    "1. **Classify** content (safe/unsafe) using a classification agent\n",
    "2. **Route** based on classification (conditional logic)\n",
    "3. **Process** safe content through enhancement\n",
    "4. **Flag** unsafe content for review\n",
    "\n",
    "Use the Microsoft Agent Framework patterns:\n",
    "- `ChatAgent` for each processing step\n",
    "- `asyncio.gather()` if parallel processing needed\n",
    "- Conditional routing with if/else based on agent output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f956038c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Content Moderation Workflow ===\n",
      "\n",
      "Input: Our Q3 earnings exceeded expectations with 15% gro...\n",
      "Status: APPROVED\n",
      "Classification: SAFE\n",
      "Output: Our Q3 earnings surpassed expectations, achieving an impressive 15% growth....\n",
      "\n",
      "Input: Meeting scheduled for Tuesday to discuss project t...\n",
      "Status: APPROVED\n",
      "Classification: SAFE\n",
      "Output: A meeting is scheduled for Tuesday to discuss and finalize the project timeline....\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exercise: Build a content moderation workflow\n",
    "\n",
    "def get_response_text(response) -> str:\n",
    "    \"\"\"Extract text from AgentRunResponse.\"\"\"\n",
    "    if isinstance(response, str):\n",
    "        return response\n",
    "    if hasattr(response, 'text') and response.text:\n",
    "        return response.text\n",
    "    if hasattr(response, 'messages') and response.messages:\n",
    "        last_msg = response.messages[-1]\n",
    "        if hasattr(last_msg, 'content'):\n",
    "            return str(last_msg.content)\n",
    "    return str(response)\n",
    "\n",
    "# Step 1: Create the agents\n",
    "classifier_agent = chat_client.create_agent(\n",
    "    name=\"Classifier\",\n",
    "    instructions=\"\"\"You are a content classifier. \n",
    "    Analyze text and respond with exactly one word: SAFE or UNSAFE.\n",
    "    SAFE = appropriate professional content\n",
    "    UNSAFE = inappropriate, harmful, or policy-violating content\"\"\"\n",
    ")\n",
    "\n",
    "enhancer_agent = chat_client.create_agent(\n",
    "    name=\"Enhancer\",\n",
    "    instructions=\"You are a content enhancer. Improve the quality and clarity of safe content.\"\n",
    ")\n",
    "\n",
    "flagger_agent = chat_client.create_agent(\n",
    "    name=\"Flagger\",\n",
    "    instructions=\"You are a content reviewer. Document why content was flagged and suggest remediation.\"\n",
    ")\n",
    "\n",
    "# Step 2: Build the moderation workflow\n",
    "async def moderate_content(content: str) -> dict:\n",
    "    \"\"\"Content moderation workflow using Agent Framework patterns.\"\"\"\n",
    "    \n",
    "    # Classify content\n",
    "    classification_response = await classifier_agent.run(f\"Classify this content: {content}\")\n",
    "    classification_text = get_response_text(classification_response)\n",
    "    is_safe = \"SAFE\" in classification_text.upper()\n",
    "    \n",
    "    # Route based on classification\n",
    "    if is_safe:\n",
    "        # Process safe content\n",
    "        enhanced = await enhancer_agent.run(f\"Enhance this content: {content}\")\n",
    "        return {\n",
    "            \"status\": \"approved\",\n",
    "            \"classification\": \"SAFE\",\n",
    "            \"result\": get_response_text(enhanced)\n",
    "        }\n",
    "    else:\n",
    "        # Flag unsafe content\n",
    "        flag_report = await flagger_agent.run(f\"Review and document why this is flagged: {content}\")\n",
    "        return {\n",
    "            \"status\": \"flagged\",\n",
    "            \"classification\": \"UNSAFE\",\n",
    "            \"result\": get_response_text(flag_report)\n",
    "        }\n",
    "\n",
    "# Test the workflow\n",
    "test_contents = [\n",
    "    \"Our Q3 earnings exceeded expectations with 15% growth.\",\n",
    "    \"Meeting scheduled for Tuesday to discuss project timeline.\"\n",
    "]\n",
    "\n",
    "print(\"=== Content Moderation Workflow ===\\n\")\n",
    "for content in test_contents:\n",
    "    print(f\"Input: {content[:50]}...\")\n",
    "    result = await moderate_content(content)\n",
    "    print(f\"Status: {result['status'].upper()}\")\n",
    "    print(f\"Classification: {result['classification']}\")\n",
    "    print(f\"Output: {result['result'][:100]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0acfcd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we explored deterministic workflow orchestration using the **Microsoft Agent Framework**:\n",
    "\n",
    "### Key Patterns Learned:\n",
    "\n",
    "| Custom Code | Agent Framework Equivalent |\n",
    "|-------------|---------------------------|\n",
    "| `WorkflowEngine.add_step()` | `WorkflowBuilder().add_edge()` |\n",
    "| `SequentialStep([steps])` | Chained `add_edge()` calls |\n",
    "| `ParallelStep([steps])` | `asyncio.gather()` with agents |\n",
    "| `ConditionalStep(cond, a, b)` | `add_edge(condition=fn)` |\n",
    "| `RetryConfig` | `RetryMiddleware` pattern |\n",
    "| `ErrorStrategy` enum | `CircuitBreaker` pattern |\n",
    "\n",
    "### Framework Benefits:\n",
    "- **Less custom code**: Leverage battle-tested framework components\n",
    "- **Standard patterns**: Use industry-standard async patterns\n",
    "- **Composability**: Combine agents and middleware flexibly\n",
    "- **Testability**: Each component is independently testable\n",
    "\n",
    "### Next Steps:\n",
    "- **Notebook 05**: Declarative agent configuration with YAML\n",
    "- **Notebook 06**: Multi-agent discussions and collaboration\n",
    "- **Notebook 07**: Evaluation and prompt evolution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (agents-workshop)",
   "language": "python",
   "name": "agents-workshop-312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
