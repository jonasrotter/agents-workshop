{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c3165f6",
   "metadata": {},
   "source": [
    "# Scenario 04: Deterministic Multi-Agent Workflows\n",
    "\n",
    "**Estimated Time**: 45 minutes\n",
    "\n",
    "## Learning Objectives\n",
    "- Design deterministic workflows for agent coordination\n",
    "- Implement sequential and parallel execution patterns\n",
    "- Handle conditional branching and error recovery\n",
    "- Use shared context for data flow between agents\n",
    "\n",
    "## Prerequisites\n",
    "- Completed Scenario 01 (Simple Agent + MCP)\n",
    "- Understanding of async/await patterns in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3eba18",
   "metadata": {},
   "source": [
    "## Part 1: Understanding Deterministic Workflows\n",
    "\n",
    "### What Are Deterministic Workflows?\n",
    "\n",
    "Deterministic workflows define a **fixed execution path** for coordinating multiple agents:\n",
    "\n",
    "- **Predictable**: Same inputs produce same execution order\n",
    "- **Debuggable**: Clear step-by-step execution trace\n",
    "- **Testable**: Each step can be tested independently\n",
    "- **Recoverable**: Built-in error handling and retry logic\n",
    "\n",
    "### Workflow vs Non-Deterministic Patterns\n",
    "\n",
    "| Deterministic | Non-Deterministic |\n",
    "|--------------|------------------|\n",
    "| Fixed execution order | Agent decides next action |\n",
    "| Explicit data flow | Implicit message passing |\n",
    "| Predictable completion | May run indefinitely |\n",
    "| Easy to test | Harder to test |\n",
    "\n",
    "### When to Use Deterministic Workflows\n",
    "\n",
    "- ETL pipelines with agent transformations\n",
    "- Document processing (extract → analyze → summarize)\n",
    "- Research workflows (search → analyze → report)\n",
    "- Approval workflows with human-in-the-loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9501b82a",
   "metadata": {},
   "source": [
    "## Part 2: Setting Up the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50230242-2614-417f-8abc-bb7b1bf407f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Project root: C:\\Users\\jonasrotter\\OneDrive - Microsoft\\Desktop\\Jonas Privat\\MyCodingProjects\\agents-workshop\n"
     ]
    }
   ],
   "source": [
    "# Load environment and configure paths\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path(\"..\").resolve()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(project_root / \".env\")\n",
    "\n",
    "print(f\"✅ Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecf3e9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Workflow components imported successfully!\n",
      "\n",
      "Error strategies: ['abort', 'skip', 'retry', 'fallback']\n"
     ]
    }
   ],
   "source": [
    "# Verify imports\n",
    "import sys\n",
    "import asyncio\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure we can import from src\n",
    "project_root = Path.cwd()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import workflow components\n",
    "from src.workflows import (\n",
    "    WorkflowEngine,\n",
    "    WorkflowResult,\n",
    "    WorkflowContext,\n",
    "    ErrorStrategy,\n",
    "    create_workflow,\n",
    "    WorkflowStep,\n",
    "    SequentialStep,\n",
    "    ParallelStep,\n",
    "    ConditionalStep,\n",
    "    DataTransform,\n",
    ")\n",
    "from src.workflows.steps import (\n",
    "    AgentStep,\n",
    "    StepStatus,\n",
    "    StepResult,\n",
    "    RetryConfig,\n",
    ")\n",
    "from src.workflows.engine import WorkflowBuilder\n",
    "from src.common.telemetry import setup_telemetry, get_tracer\n",
    "\n",
    "# Setup telemetry\n",
    "setup_telemetry()\n",
    "tracer = get_tracer(__name__)\n",
    "\n",
    "print(\"✅ Workflow components imported successfully!\")\n",
    "print(f\"\\nError strategies: {[s.value for s in ErrorStrategy]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c03a0e",
   "metadata": {},
   "source": [
    "## Part 3: Basic Workflow Structure\n",
    "\n",
    "Let's start with a simple workflow using custom steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d881fa5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: completed\n",
      "Final output: [Step 3]: [Step 2]: [Step 1]: Hello, Workflow!\n",
      "Duration: 0.52ms\n"
     ]
    }
   ],
   "source": [
    "# Create a simple custom step\n",
    "class EchoStep(WorkflowStep):\n",
    "    \"\"\"A simple step that echoes input with a prefix.\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, prefix: str):\n",
    "        super().__init__(name)\n",
    "        self.prefix = prefix\n",
    "    \n",
    "    async def execute(self, inputs, context):\n",
    "        import time\n",
    "        start = time.time()\n",
    "        \n",
    "        message = inputs.get(\"message\", \"\")\n",
    "        result = f\"{self.prefix}: {message}\"\n",
    "        \n",
    "        return StepResult(\n",
    "            step_name=self.name,\n",
    "            status=StepStatus.COMPLETED,\n",
    "            outputs={\"message\": result},\n",
    "            duration_ms=(time.time() - start) * 1000\n",
    "        )\n",
    "\n",
    "# Create workflow engine\n",
    "engine = WorkflowEngine(name=\"echo_pipeline\")\n",
    "\n",
    "# Add steps\n",
    "engine.add_step(EchoStep(\"step1\", \"[Step 1]\"))\n",
    "engine.add_step(EchoStep(\"step2\", \"[Step 2]\"))\n",
    "engine.add_step(EchoStep(\"step3\", \"[Step 3]\"))\n",
    "\n",
    "# Execute workflow\n",
    "result = await engine.execute({\"message\": \"Hello, Workflow!\"})\n",
    "\n",
    "print(f\"Status: {result.status.value}\")\n",
    "print(f\"Final output: {result.outputs['message']}\")\n",
    "print(f\"Duration: {result.duration_ms:.2f}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c6816b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step Results ===\n",
      "  step1: completed\n",
      "    Output: {'message': '[Step 1]: Hello, Workflow!'}\n",
      "  step2: completed\n",
      "    Output: {'message': '[Step 2]: [Step 1]: Hello, Workflow!'}\n",
      "  step3: completed\n",
      "    Output: {'message': '[Step 3]: [Step 2]: [Step 1]: Hello, Workflow!'}\n"
     ]
    }
   ],
   "source": [
    "# Inspect step results\n",
    "print(\"=== Step Results ===\")\n",
    "for name, step_result in result.step_results.items():\n",
    "    print(f\"  {name}: {step_result.status.value}\")\n",
    "    print(f\"    Output: {step_result.outputs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6fa91e",
   "metadata": {},
   "source": [
    "## Part 4: Sequential Step Composition\n",
    "\n",
    "Group steps into sequential containers for logical organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01c6bfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 'hello world'\n",
      "Output: 'DLROW OLLEH (length: 11)'\n"
     ]
    }
   ],
   "source": [
    "# Create processing step\n",
    "class ProcessingStep(WorkflowStep):\n",
    "    \"\"\"A step that processes data.\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, operation: str):\n",
    "        super().__init__(name)\n",
    "        self.operation = operation\n",
    "    \n",
    "    async def execute(self, inputs, context):\n",
    "        import time\n",
    "        start = time.time()\n",
    "        \n",
    "        data = inputs.get(\"data\", \"\")\n",
    "        \n",
    "        if self.operation == \"uppercase\":\n",
    "            result = data.upper()\n",
    "        elif self.operation == \"reverse\":\n",
    "            result = data[::-1]\n",
    "        elif self.operation == \"count\":\n",
    "            result = f\"{data} (length: {len(data)})\"\n",
    "        else:\n",
    "            result = data\n",
    "        \n",
    "        return StepResult(\n",
    "            step_name=self.name,\n",
    "            status=StepStatus.COMPLETED,\n",
    "            outputs={\"data\": result},\n",
    "            duration_ms=(time.time() - start) * 1000\n",
    "        )\n",
    "\n",
    "# Create a sequential step container\n",
    "text_pipeline = SequentialStep(\n",
    "    name=\"text_processing\",\n",
    "    steps=[\n",
    "        ProcessingStep(\"uppercase\", \"uppercase\"),\n",
    "        ProcessingStep(\"reverse\", \"reverse\"),\n",
    "        ProcessingStep(\"count\", \"count\"),\n",
    "    ],\n",
    "    description=\"Process text through multiple transformations\"\n",
    ")\n",
    "\n",
    "# Execute\n",
    "context = WorkflowContext(workflow_name=\"demo\")\n",
    "result = await text_pipeline.execute({\"data\": \"hello world\"}, context)\n",
    "\n",
    "print(f\"Input: 'hello world'\")\n",
    "print(f\"Output: '{result.outputs['data']}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a46748",
   "metadata": {},
   "source": [
    "## Part 5: Parallel Step Execution\n",
    "\n",
    "Execute multiple steps concurrently when they're independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "708eaffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: completed\n",
      "Duration: 516.20ms (parallel!)\n",
      "\n",
      "=== Outputs ===\n",
      "  sentiment: Analysis of 'The quick brown fox ...'\n",
      "  entities: Analysis of 'The quick brown fox ...'\n",
      "  topics: Analysis of 'The quick brown fox ...'\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "# Create steps with simulated delay\n",
    "class AnalysisStep(WorkflowStep):\n",
    "    \"\"\"A step that performs analysis with simulated delay.\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, analysis_type: str, delay: float = 0.5):\n",
    "        super().__init__(name)\n",
    "        self.analysis_type = analysis_type\n",
    "        self.delay = delay\n",
    "    \n",
    "    async def execute(self, inputs, context):\n",
    "        import time\n",
    "        start = time.time()\n",
    "        \n",
    "        # Simulate analysis work\n",
    "        await asyncio.sleep(self.delay)\n",
    "        \n",
    "        data = inputs.get(\"text\", \"\")\n",
    "        \n",
    "        return StepResult(\n",
    "            step_name=self.name,\n",
    "            status=StepStatus.COMPLETED,\n",
    "            outputs={self.analysis_type: f\"Analysis of '{data[:20]}...'\"},\n",
    "            duration_ms=(time.time() - start) * 1000\n",
    "        )\n",
    "\n",
    "# Create parallel analysis\n",
    "parallel_analysis = ParallelStep(\n",
    "    name=\"parallel_analysis\",\n",
    "    steps=[\n",
    "        AnalysisStep(\"sentiment\", \"sentiment\", 0.3),\n",
    "        AnalysisStep(\"entities\", \"entities\", 0.4),\n",
    "        AnalysisStep(\"topics\", \"topics\", 0.5),\n",
    "    ]\n",
    ")\n",
    "\n",
    "context = WorkflowContext(workflow_name=\"parallel_demo\")\n",
    "result = await parallel_analysis.execute(\n",
    "    {\"text\": \"The quick brown fox jumps over the lazy dog.\"},\n",
    "    context\n",
    ")\n",
    "\n",
    "print(f\"Status: {result.status.value}\")\n",
    "print(f\"Duration: {result.duration_ms:.2f}ms (parallel!)\")\n",
    "print(\"\\n=== Outputs ===\")\n",
    "for key, value in result.outputs.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2760f0d",
   "metadata": {},
   "source": [
    "## Part 6: Conditional Branching\n",
    "\n",
    "Execute different paths based on conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "722b0acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short text result: {'data': 'SHORT'}\n",
      "Long text result: AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA...\n"
     ]
    }
   ],
   "source": [
    "# Define condition function\n",
    "def is_long_text(inputs, context):\n",
    "    \"\"\"Check if text is longer than threshold.\"\"\"\n",
    "    text = inputs.get(\"text\", \"\")\n",
    "    return len(text) > 100\n",
    "\n",
    "# Create conditional step\n",
    "conditional_processing = ConditionalStep(\n",
    "    name=\"length_check\",\n",
    "    condition=is_long_text,\n",
    "    then_step=ProcessingStep(\"summarize\", \"count\"),  # Long text\n",
    "    else_step=ProcessingStep(\"expand\", \"uppercase\"),  # Short text\n",
    "    description=\"Process differently based on text length\"\n",
    ")\n",
    "\n",
    "# Test with short text\n",
    "context = WorkflowContext(workflow_name=\"conditional_demo\")\n",
    "short_result = await conditional_processing.execute(\n",
    "    {\"text\": \"short\", \"data\": \"short\"},\n",
    "    context\n",
    ")\n",
    "print(f\"Short text result: {short_result.outputs}\")\n",
    "\n",
    "# Test with long text\n",
    "long_text = \"A\" * 150\n",
    "long_result = await conditional_processing.execute(\n",
    "    {\"text\": long_text, \"data\": long_text},\n",
    "    context\n",
    ")\n",
    "print(f\"Long text result: {long_result.outputs.get('data', '')[:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7013b87e",
   "metadata": {},
   "source": [
    "## Part 7: Data Transformations\n",
    "\n",
    "Transform data between steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67ec02ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords: ['artificial', 'intelligence', 'revolution', 'transforming', 'industries']\n"
     ]
    }
   ],
   "source": [
    "# Create data transform\n",
    "def extract_keywords(inputs):\n",
    "    \"\"\"Extract simple keywords from text.\"\"\"\n",
    "    text = inputs.get(\"text\", \"\")\n",
    "    # Simple keyword extraction (in real app, use NLP)\n",
    "    words = text.lower().split()\n",
    "    keywords = [w for w in words if len(w) > 4]\n",
    "    return {\"keywords\": keywords[:5]}\n",
    "\n",
    "transform_step = DataTransform(\n",
    "    name=\"extract_keywords\",\n",
    "    transform=extract_keywords,\n",
    "    description=\"Extract keywords from text\"\n",
    ")\n",
    "\n",
    "context = WorkflowContext(workflow_name=\"transform_demo\")\n",
    "result = await transform_step.execute(\n",
    "    {\"text\": \"The artificial intelligence revolution is transforming industries worldwide.\"},\n",
    "    context\n",
    ")\n",
    "\n",
    "print(f\"Keywords: {result.outputs['keywords']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f0ceca",
   "metadata": {},
   "source": [
    "## Part 8: Error Handling Strategies\n",
    "\n",
    "Configure how the workflow responds to failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f23ab915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a failing step\n",
    "class FailingStep(WorkflowStep):\n",
    "    \"\"\"A step that fails on certain inputs.\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, fail_on: str):\n",
    "        super().__init__(name)\n",
    "        self.fail_on = fail_on\n",
    "    \n",
    "    async def execute(self, inputs, context):\n",
    "        data = inputs.get(\"data\", \"\")\n",
    "        \n",
    "        if self.fail_on in data:\n",
    "            return StepResult(\n",
    "                step_name=self.name,\n",
    "                status=StepStatus.FAILED,\n",
    "                error=f\"Found forbidden value: {self.fail_on}\"\n",
    "            )\n",
    "        \n",
    "        return StepResult(\n",
    "            step_name=self.name,\n",
    "            status=StepStatus.COMPLETED,\n",
    "            outputs={\"data\": f\"processed: {data}\"}\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f71545c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABORT Strategy:\n",
      "  Status: failed\n",
      "  Error: Step 'step2' failed: Failed after 1 attempts: Found forbidden value: error\n",
      "  Steps completed: 1\n"
     ]
    }
   ],
   "source": [
    "# Test ABORT strategy (default)\n",
    "from src.workflows.engine import ErrorConfig\n",
    "\n",
    "abort_engine = WorkflowEngine(\n",
    "    name=\"abort_test\",\n",
    "    error_config=ErrorConfig(strategy=ErrorStrategy.ABORT)\n",
    ")\n",
    "abort_engine.add_step(EchoStep(\"step1\", \"[1]\"))\n",
    "abort_engine.add_step(FailingStep(\"step2\", \"error\"))\n",
    "abort_engine.add_step(EchoStep(\"step3\", \"[3]\"))\n",
    "\n",
    "result = await abort_engine.execute({\"message\": \"test\", \"data\": \"error here\"})\n",
    "print(f\"ABORT Strategy:\")\n",
    "print(f\"  Status: {result.status.value}\")\n",
    "print(f\"  Error: {result.error}\")\n",
    "print(f\"  Steps completed: {len([r for r in result.step_results.values() if r.succeeded])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "868b84f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKIP Strategy:\n",
      "  Status: completed\n",
      "  Steps completed: 2\n",
      "  Final message: [3]: [1]: test\n"
     ]
    }
   ],
   "source": [
    "# Test SKIP strategy\n",
    "skip_engine = WorkflowEngine(\n",
    "    name=\"skip_test\",\n",
    "    error_config=ErrorConfig(strategy=ErrorStrategy.SKIP)\n",
    ")\n",
    "skip_engine.add_step(EchoStep(\"step1\", \"[1]\"))\n",
    "skip_engine.add_step(FailingStep(\"step2\", \"error\"))\n",
    "skip_engine.add_step(EchoStep(\"step3\", \"[3]\"))\n",
    "\n",
    "result = await skip_engine.execute({\"message\": \"test\", \"data\": \"error here\"})\n",
    "print(f\"SKIP Strategy:\")\n",
    "print(f\"  Status: {result.status.value}\")\n",
    "print(f\"  Steps completed: {len([r for r in result.step_results.values() if r.succeeded])}\")\n",
    "print(f\"  Final message: {result.outputs.get('message', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7baf4d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FALLBACK Strategy:\n",
      "  Status: completed\n",
      "  Fallback used: True\n"
     ]
    }
   ],
   "source": [
    "# Test FALLBACK strategy\n",
    "fallback_engine = WorkflowEngine(\n",
    "    name=\"fallback_test\",\n",
    "    error_config=ErrorConfig(\n",
    "        strategy=ErrorStrategy.FALLBACK,\n",
    "        fallback_value=\"default_value\"\n",
    "    )\n",
    ")\n",
    "fallback_engine.add_step(EchoStep(\"step1\", \"[1]\"))\n",
    "fallback_engine.add_step(FailingStep(\"step2\", \"error\"))\n",
    "fallback_engine.add_step(EchoStep(\"step3\", \"[3]\"))\n",
    "\n",
    "result = await fallback_engine.execute({\"message\": \"test\", \"data\": \"error here\"})\n",
    "print(f\"FALLBACK Strategy:\")\n",
    "print(f\"  Status: {result.status.value}\")\n",
    "print(f\"  Fallback used: {'fallback' in result.outputs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6cba39",
   "metadata": {},
   "source": [
    "## Part 9: Retry Configuration\n",
    "\n",
    "Configure automatic retries for flaky steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25c41c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retry Result:\n",
      "  Status: completed\n",
      "  Total attempts: 1\n",
      "  Result: Success after 1 attempts!\n"
     ]
    }
   ],
   "source": [
    "# Create a flaky step that sometimes fails\n",
    "import random\n",
    "\n",
    "class FlakyStep(WorkflowStep):\n",
    "    \"\"\"A step that randomly fails.\"\"\"\n",
    "    \n",
    "    attempt_count = 0\n",
    "    \n",
    "    def __init__(self, name: str, success_rate: float = 0.3):\n",
    "        retry = RetryConfig(max_attempts=5, delay_seconds=0.1)\n",
    "        super().__init__(name, retry=retry)\n",
    "        self.success_rate = success_rate\n",
    "    \n",
    "    async def execute(self, inputs, context):\n",
    "        FlakyStep.attempt_count += 1\n",
    "        \n",
    "        if random.random() > self.success_rate:\n",
    "            return StepResult(\n",
    "                step_name=self.name,\n",
    "                status=StepStatus.FAILED,\n",
    "                error=f\"Random failure (attempt {FlakyStep.attempt_count})\"\n",
    "            )\n",
    "        \n",
    "        return StepResult(\n",
    "            step_name=self.name,\n",
    "            status=StepStatus.COMPLETED,\n",
    "            outputs={\"result\": f\"Success after {FlakyStep.attempt_count} attempts!\"}\n",
    "        )\n",
    "\n",
    "# Reset counter\n",
    "FlakyStep.attempt_count = 0\n",
    "\n",
    "# Create workflow with retry\n",
    "retry_engine = WorkflowEngine(\n",
    "    name=\"retry_test\",\n",
    "    error_config=ErrorConfig(strategy=ErrorStrategy.RETRY)\n",
    ")\n",
    "retry_engine.add_step(FlakyStep(\"flaky_step\", success_rate=0.3))\n",
    "\n",
    "result = await retry_engine.execute({})\n",
    "print(f\"Retry Result:\")\n",
    "print(f\"  Status: {result.status.value}\")\n",
    "print(f\"  Total attempts: {FlakyStep.attempt_count}\")\n",
    "if result.succeeded:\n",
    "    print(f\"  Result: {result.outputs.get('result')}\")\n",
    "else:\n",
    "    print(f\"  Error: {result.error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea3edda",
   "metadata": {},
   "source": [
    "## Part 10: Using the Workflow Builder\n",
    "\n",
    "Fluent API for building workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "474abf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: completed\n",
      "Duration: 0.96ms\n",
      "\n",
      "=== Output ===\n",
      "Summary: Executive summary | Input: Summarize this analysis: Analysis results | Input:...\n"
     ]
    }
   ],
   "source": [
    "# Create mock agents for demonstration\n",
    "class MockAgent:\n",
    "    def __init__(self, name: str, response: str):\n",
    "        self.name = name\n",
    "        self.response = response\n",
    "    \n",
    "    async def run(self, prompt: str) -> str:\n",
    "        return f\"{self.response} | Input: {prompt[:50]}...\"\n",
    "\n",
    "# Create workflow using builder\n",
    "workflow = (\n",
    "    WorkflowBuilder(\"research_pipeline\")\n",
    "    .with_description(\"Research and summarize a topic\")\n",
    "    .with_agent(\"researcher\", MockAgent(\"researcher\", \"Research findings\"))\n",
    "    .with_agent(\"analyzer\", MockAgent(\"analyzer\", \"Analysis results\"))\n",
    "    .with_agent(\"summarizer\", MockAgent(\"summarizer\", \"Executive summary\"))\n",
    "    .add_agent_step(\n",
    "        name=\"research\",\n",
    "        agent=\"researcher\",\n",
    "        prompt=\"Research the following topic: {topic}\",\n",
    "        outputs=[\"findings\"]\n",
    "    )\n",
    "    .add_agent_step(\n",
    "        name=\"analyze\",\n",
    "        agent=\"analyzer\",\n",
    "        prompt=\"Analyze these findings: {findings}\",\n",
    "        outputs=[\"analysis\"]\n",
    "    )\n",
    "    .add_agent_step(\n",
    "        name=\"summarize\",\n",
    "        agent=\"summarizer\",\n",
    "        prompt=\"Summarize this analysis: {analysis}\",\n",
    "        outputs=[\"summary\"]\n",
    "    )\n",
    "    .on_error(ErrorStrategy.ABORT)\n",
    "    .build()\n",
    ")\n",
    "\n",
    "# Execute\n",
    "result = await workflow.execute({\"topic\": \"AI agents in production\"})\n",
    "\n",
    "print(f\"Status: {result.status.value}\")\n",
    "print(f\"Duration: {result.duration_ms:.2f}ms\")\n",
    "print(f\"\\n=== Output ===\")\n",
    "print(f\"Summary: {result.outputs.get('summary', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0245b31",
   "metadata": {},
   "source": [
    "## Part 11: Workflow Validation\n",
    "\n",
    "Validate workflows before execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4947a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty workflow errors: ['Workflow has no steps']\n",
      "Missing agent errors: [\"Step 'step1' references unregistered agent 'unknown_agent'\"]\n"
     ]
    }
   ],
   "source": [
    "# Create an invalid workflow\n",
    "invalid_workflow = WorkflowEngine(name=\"invalid\")\n",
    "\n",
    "# Empty workflow\n",
    "errors = invalid_workflow.validate()\n",
    "print(\"Empty workflow errors:\", errors)\n",
    "\n",
    "# Add step referencing unknown agent\n",
    "invalid_workflow.add_step(AgentStep(\n",
    "    name=\"step1\",\n",
    "    agent_name=\"unknown_agent\",\n",
    "    prompt_template=\"Hello\",\n",
    "    output_vars=[\"result\"]\n",
    "))\n",
    "\n",
    "errors = invalid_workflow.validate()\n",
    "print(\"Missing agent errors:\", errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe21835",
   "metadata": {},
   "source": [
    "## Part 12: Hands-On Exercise\n",
    "\n",
    "### Exercise: Build a Document Processing Workflow\n",
    "\n",
    "Create a workflow that:\n",
    "1. Extracts text from a document\n",
    "2. Analyzes sentiment (parallel: positive, negative, neutral)\n",
    "3. Generates a summary\n",
    "4. Adds metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f956038c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: completed\n",
      "Outputs: {'text': 'Extracted text from: quarterly_report.pdf', 'positive_score': 0.5, 'negative_score': 0.5, 'neutral_score': 0.5}\n"
     ]
    }
   ],
   "source": [
    "# Exercise: Complete this workflow\n",
    "\n",
    "# Step 1: Create extraction step\n",
    "class ExtractTextStep(WorkflowStep):\n",
    "    async def execute(self, inputs, context):\n",
    "        document = inputs.get(\"document\", \"\")\n",
    "        # Simulate text extraction\n",
    "        text = f\"Extracted text from: {document}\"\n",
    "        return StepResult(\n",
    "            step_name=self.name,\n",
    "            status=StepStatus.COMPLETED,\n",
    "            outputs={\"text\": text}\n",
    "        )\n",
    "\n",
    "# Step 2: Create sentiment analysis steps (parallel)\n",
    "# TODO: Create SentimentStep class\n",
    "class SentimentStep(WorkflowStep):\n",
    "    def __init__(self, name: str, sentiment_type: str):\n",
    "        super().__init__(name)\n",
    "        self.sentiment_type = sentiment_type\n",
    "    \n",
    "    async def execute(self, inputs, context):\n",
    "        text = inputs.get(\"text\", \"\")\n",
    "        # TODO: Implement sentiment scoring\n",
    "        score = 0.5  # Placeholder\n",
    "        return StepResult(\n",
    "            step_name=self.name,\n",
    "            status=StepStatus.COMPLETED,\n",
    "            outputs={f\"{self.sentiment_type}_score\": score}\n",
    "        )\n",
    "\n",
    "# Step 3: Build the workflow\n",
    "doc_workflow = WorkflowEngine(name=\"document_processing\")\n",
    "\n",
    "# TODO: Add steps\n",
    "doc_workflow.add_step(ExtractTextStep(\"extract\"))\n",
    "doc_workflow.add_step(ParallelStep(\n",
    "    name=\"sentiment_analysis\",\n",
    "    steps=[\n",
    "        SentimentStep(\"positive\", \"positive\"),\n",
    "        SentimentStep(\"negative\", \"negative\"),\n",
    "        SentimentStep(\"neutral\", \"neutral\"),\n",
    "    ]\n",
    "))\n",
    "\n",
    "# Execute\n",
    "result = await doc_workflow.execute({\"document\": \"quarterly_report.pdf\"})\n",
    "print(f\"Status: {result.status.value}\")\n",
    "print(f\"Outputs: {result.outputs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0acfcd",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this scenario, you learned:\n",
    "\n",
    "1. **Deterministic Workflows**: Fixed execution paths for multi-agent coordination\n",
    "2. **Step Types**: Sequential, parallel, conditional, and transform steps\n",
    "3. **Error Handling**: Abort, skip, retry, and fallback strategies\n",
    "4. **Data Flow**: Passing outputs between steps\n",
    "5. **Workflow Builder**: Fluent API for workflow construction\n",
    "6. **Validation**: Checking workflow configuration before execution\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- Deterministic workflows provide predictability and debuggability\n",
    "- Use sequential steps for dependent operations\n",
    "- Use parallel steps for independent operations\n",
    "- Configure error strategies based on your reliability requirements\n",
    "- Always validate workflows before execution\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- **Scenario 5**: Declarative agent configuration with YAML\n",
    "- **Scenario 6**: Moderated agent discussions\n",
    "\n",
    "## Resources\n",
    "\n",
    "- [Data Model](specs/001-agentic-patterns-workshop/data-model.md)\n",
    "- [Workflow Patterns](https://www.enterpriseintegrationpatterns.com/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
