{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13279e2b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Scenario 01: Simple Agent with MCP Tools\n",
    "\n",
    "**Estimated Time**: 30 minutes\n",
    "\n",
    "## Learning Objectives\n",
    "- Create a base agent using the Microsoft Agent Framework\n",
    "- Integrate MCP tools for extended capabilities\n",
    "- Implement OpenTelemetry observability\n",
    "- Understand the agent execution lifecycle\n",
    "\n",
    "## Prerequisites\n",
    "- Completed Scenario 00 (Environment Setup)\n",
    "- Azure OpenAI API access configured"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f459dc",
   "metadata": {},
   "source": [
    "## Part 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1118fbc1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Project root: C:\\Users\\jonasrotter\\OneDrive - Microsoft\\Desktop\\Jonas Privat\\MyCodingProjects\\agents-workshop\n"
     ]
    }
   ],
   "source": [
    "# Load environment and configure paths\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path(\"..\").resolve()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(project_root / \".env\")\n",
    "\n",
    "print(f\"âœ… Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9eb40cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Telemetry initialized\n",
      "   Azure OpenAI: Configured\n",
      "   Observability: Azure Monitor\n",
      "   OpenAI Deployment: Azure OpenAI Deployment Name\n"
     ]
    }
   ],
   "source": [
    "# Initialize telemetry for observability\n",
    "from src.common.telemetry import setup_telemetry, get_tracer\n",
    "from src.common.config import get_settings\n",
    "\n",
    "# Clear any cached settings and setup telemetry\n",
    "get_settings.cache_clear()\n",
    "setup_telemetry()\n",
    "\n",
    "settings = get_settings()\n",
    "print(f\"âœ… Telemetry initialized\")\n",
    "print(f\"   Azure OpenAI: {'Configured' if settings.is_azure_configured else 'Not configured'}\")\n",
    "print(f\"   Observability: {'Azure Monitor' if settings.is_observability_configured else 'Console export'}\")\n",
    "print(f\"   OpenAI Deployment: {'Azure OpenAI Deployment Name' if settings.azure_openai_deployment else 'Deployment Name not set'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d748e6d",
   "metadata": {},
   "source": [
    "## Part 2: Understanding MCP Tools\n",
    "\n",
    "Before we connect tools to an agent, let's explore the tools available in our workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1f026f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the workshop tools\n",
    "from src.tools import search_web, get_weather, calculate, read_file, write_file\n",
    "\n",
    "# These tools are also available through the MCP server\n",
    "from src.tools.mcp_server import TOOLS\n",
    "\n",
    "print(\"Available MCP Tools:\")\n",
    "print(\"=\"*50)\n",
    "for tool in TOOLS:\n",
    "    print(f\"\\nðŸ“¦ {tool.name}\")\n",
    "    print(f\"   {tool.description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df56f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test a tool directly\n",
    "print(\"Testing search_web tool directly:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "result = await search_web(\"python programming\", max_results=3)\n",
    "\n",
    "print(f\"Found {result['total_found']} results:\")\n",
    "for item in result['results']:\n",
    "    print(f\"\\n  ðŸ“„ {item['title']}\")\n",
    "    print(f\"     {item['url']}\")\n",
    "    print(f\"     {item['snippet'][:80]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883b2b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the calculator tool\n",
    "print(\"Testing calculate tool:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "operations = [\n",
    "    (\"add\", 11, 27),\n",
    "    (\"multiply\", 7, 8),\n",
    "    (\"sqrt\", 144, None),\n",
    "    (\"power\", 2, 10),\n",
    "]\n",
    "\n",
    "for op, a, b in operations:\n",
    "    result = await calculate(op, a, b)\n",
    "    print(f\"  {result['expression']} = {result['result']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2d19d7",
   "metadata": {},
   "source": [
    "## Part 3: Creating a Simple Agent\n",
    "\n",
    "Now let's create an agent that can use these tools to accomplish tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc27c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.agents import ResearchAgent\n",
    "from src.tools import search_web, get_weather, calculate\n",
    "\n",
    "# Create a research agent\n",
    "agent = ResearchAgent(\n",
    "    name=\"workshop_researcher\",\n",
    "    #temperature=0.7,\n",
    "    max_tool_iterations=5,\n",
    ")\n",
    "\n",
    "# Register tool handlers\n",
    "agent.set_tool_handlers({\n",
    "    \"search_web\": search_web,\n",
    "    \"get_weather\": get_weather,\n",
    "    \"calculate\": calculate,\n",
    "})\n",
    "\n",
    "print(f\"âœ… Created agent: {agent.name}\")\n",
    "print(f\"   Model: {agent.model}\")\n",
    "print(f\"   Tools registered: {len(agent._tool_handlers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebdcf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a simple research task\n",
    "print(\"Running research task...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "task = \"What is the weather like in Seattle? Also calculate 15% of 250.\"\n",
    "\n",
    "try:\n",
    "    result = await agent.run(task)\n",
    "    print(\"\\nAgent Response:\")\n",
    "    print(\"-\"*50)\n",
    "    print(result)\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ Error: {e}\")\n",
    "    print(\"\\nNote: If Azure OpenAI is not configured, the agent cannot run.\")\n",
    "    print(\"Check your .env file and ensure AZURE_OPENAI_ENDPOINT is set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fdc934",
   "metadata": {},
   "source": [
    "## Part 4: Observing Agent Behavior with Traces\n",
    "\n",
    "One of the key aspects of building production agents is observability. Let's examine the traces generated by our agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc97d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.common.telemetry import get_current_span, get_tracer\n",
    "\n",
    "tracer = get_tracer(\"notebook_01\")\n",
    "\n",
    "# Create a traced operation\n",
    "with tracer.start_as_current_span(\"demo_trace\") as span:\n",
    "    span.set_attribute(\"demo.operation\", \"trace_demo\")\n",
    "    span.set_attribute(\"demo.notebook\", \"01_simple_agent_mcp\")\n",
    "    \n",
    "    # Perform a tool operation within the span\n",
    "    result = await search_web(\"azure openai\", max_results=2)\n",
    "    \n",
    "    span.set_attribute(\"demo.results_count\", result['total_found'])\n",
    "    span.add_event(\"search_completed\", {\"query\": \"azure openai\"})\n",
    "\n",
    "print(\"âœ… Trace created and exported\")\n",
    "print(\"\")\n",
    "print(\"If using Azure Monitor, traces will appear in:\")\n",
    "print(\"  Azure Portal > Application Insights > Transaction search\")\n",
    "print(\"\")\n",
    "print(\"If using console export, check the terminal output for trace data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf48408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate trace attributes for agent operations\n",
    "from src.common.telemetry import create_span_attributes\n",
    "\n",
    "# These are the attributes we track for agent operations\n",
    "agent_attrs = create_span_attributes(\n",
    "    agent_name=\"demo_agent\",\n",
    "    model=\"gpt-4o\",\n",
    "    prompt_tokens=150,\n",
    "    completion_tokens=75,\n",
    ")\n",
    "\n",
    "print(\"Agent Span Attributes:\")\n",
    "print(\"-\"*40)\n",
    "for key, value in agent_attrs.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Tool attributes\n",
    "tool_attrs = create_span_attributes(\n",
    "    tool_name=\"search_web\",\n",
    "    query=\"python async\",\n",
    ")\n",
    "\n",
    "print(\"\\nTool Span Attributes:\")\n",
    "print(\"-\"*40)\n",
    "for key, value in tool_attrs.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bd8aba",
   "metadata": {},
   "source": [
    "## Part 5: Handling MCP Server Unavailability (Edge Case)\n",
    "\n",
    "In production, external services can fail. Let's explore graceful degradation patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad619a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.common.exceptions import MCPError, ToolError\n",
    "\n",
    "async def resilient_tool_call(tool_name: str, tool_func, **kwargs):\n",
    "    \"\"\"Execute a tool with graceful error handling.\"\"\"\n",
    "    try:\n",
    "        result = await tool_func(**kwargs)\n",
    "        return {\"success\": True, \"data\": result}\n",
    "    except ToolError as e:\n",
    "        print(f\"âš ï¸ Tool error: {e}\")\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": str(e),\n",
    "            \"fallback\": \"Using cached or default data\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Unexpected error: {e}\")\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": str(e),\n",
    "            \"fallback\": \"Service unavailable\"\n",
    "        }\n",
    "\n",
    "# Test with valid call\n",
    "print(\"Testing resilient tool call:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "result = await resilient_tool_call(\"search_web\", search_web, query=\"test\")\n",
    "print(f\"Success: {result['success']}\")\n",
    "\n",
    "# Test with invalid parameters (will trigger error handling)\n",
    "result = await resilient_tool_call(\"calculate\", calculate, operation=\"divide\", a=10, b=0)\n",
    "print(f\"\\nDivision by zero handled gracefully: {result['success']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6b6a82",
   "metadata": {},
   "source": [
    "## Part 6: Hands-On Exercise ðŸŽ¯\n",
    "\n",
    "Now it's your turn! Add a new tool to the agent.\n",
    "\n",
    "### Exercise: Create a Text Analysis Tool\n",
    "\n",
    "Create a tool that analyzes text and returns:\n",
    "- Word count\n",
    "- Character count\n",
    "- Average word length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967bafe9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Implement the analyze_text tool\n",
    "\n",
    "async def analyze_text(text: str) -> dict:\n",
    "    \"\"\"Analyze text and return statistics.\n",
    "    \n",
    "    Args:\n",
    "        text: The text to analyze.\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with word_count, char_count, avg_word_length.\n",
    "    \"\"\"\n",
    "    # TODO: Implement this function\n",
    "    # Hints:\n",
    "    # 1. Split text into words using text.split()\n",
    "    # 2. Count characters with len(text)\n",
    "    # 3. Calculate average word length\n",
    "    \n",
    "    words = text.split()\n",
    "    word_count = len(words)\n",
    "    char_count = len(text)\n",
    "    avg_word_length = sum(len(w) for w in words) / word_count if word_count > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        \"word_count\": word_count,\n",
    "        \"char_count\": char_count,\n",
    "        \"avg_word_length\": round(avg_word_length, 2),\n",
    "    }\n",
    "\n",
    "# Test your implementation\n",
    "test_text = \"The quick brown fox jumps over the lazy dog\"\n",
    "result = await analyze_text(test_text)\n",
    "print(f\"Analysis of: '{test_text}'\")\n",
    "print(f\"  Word count: {result['word_count']}\")\n",
    "print(f\"  Character count: {result['char_count']}\")\n",
    "print(f\"  Average word length: {result['avg_word_length']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2019f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS: Add your new tool to the agent\n",
    "\n",
    "# Create a new agent with the additional tool\n",
    "enhanced_agent = ResearchAgent(\n",
    "    name=\"enhanced_researcher\",\n",
    "    system_prompt=\"\"\"You are a research assistant with text analysis capabilities.\n",
    "    \n",
    "    You can:\n",
    "    - Search the web for information\n",
    "    - Perform calculations\n",
    "    - Analyze text for statistics\n",
    "    \n",
    "    When asked about text, use the analyze_text tool.\"\"\",\n",
    ")\n",
    "\n",
    "enhanced_agent.set_tool_handlers({\n",
    "    \"search_web\": search_web,\n",
    "    \"calculate\": calculate,\n",
    "    \"analyze_text\": analyze_text,  # Your new tool!\n",
    "})\n",
    "\n",
    "print(f\"âœ… Enhanced agent created with {len(enhanced_agent._tool_handlers)} tools\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf601342",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this scenario, you learned:\n",
    "\n",
    "1. **MCP Tools**: How to create and use tools that follow the Model Context Protocol\n",
    "2. **Agent Creation**: How to build agents with Azure OpenAI that can use tools\n",
    "3. **Observability**: How to add OpenTelemetry tracing to observe agent behavior\n",
    "4. **Error Handling**: How to handle tool failures gracefully\n",
    "5. **Tool Extension**: How to add new tools to extend agent capabilities\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "- **MCP** provides a standardized way to expose tools to AI models\n",
    "- **Telemetry** helps you understand what your agent is doing\n",
    "- **Graceful degradation** ensures your agent remains useful even when tools fail\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Continue to **02_agui_interface.ipynb** to learn about building user interfaces for agents using the AG-UI protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bf8d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "await agent.close()\n",
    "print(\"âœ… Scenario 1 complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (agents-workshop)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
