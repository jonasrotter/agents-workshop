





# Load environment and configure paths
import sys
from pathlib import Path

# Add project root to path
project_root = Path("..").resolve()
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

# Load environment variables
from dotenv import load_dotenv
load_dotenv(project_root / ".env")

print(f"âœ… Project root: {project_root}")


# Initialize telemetry for observability
from src.common.telemetry import setup_telemetry, get_tracer
from src.common.config import get_settings

# Clear any cached settings and setup telemetry
get_settings.cache_clear()
setup_telemetry()

settings = get_settings()
print(f"âœ… Telemetry initialized")
print(f"   Azure OpenAI: {'Configured' if settings.is_azure_configured else 'Not configured'}")
print(f"   Observability: {'Azure Monitor' if settings.is_observability_configured else 'Console export'}")
print(f"   OpenAI Deployment: {'Azure OpenAI Deployment Name' if settings.azure_openai_deployment else 'Deployment Name not set'}")





# Import the workshop tools
from src.tools import search_web, get_weather, calculate, read_file, write_file

# These tools are also available through the MCP server
from src.tools.mcp_server import TOOLS

print("Available MCP Tools:")
print("="*50)
for tool in TOOLS:
    print(f"\nðŸ“¦ {tool.name}")
    print(f"   {tool.description}")


# Let's test a tool directly
print("Testing search_web tool directly:")
print("="*50)

result = await search_web("python programming", max_results=3)

print(f"Found {result['total_found']} results:")
for item in result['results']:
    print(f"\n  ðŸ“„ {item['title']}")
    print(f"     {item['url']}")
    print(f"     {item['snippet'][:80]}...")


# Test the calculator tool
print("Testing calculate tool:")
print("="*50)

operations = [
    ("add", 11, 27),
    ("multiply", 7, 8),
    ("sqrt", 144, None),
    ("power", 2, 10),
]

for op, a, b in operations:
    result = await calculate(op, a, b)
    print(f"  {result['expression']} = {result['result']}")





from src.agents import ResearchAgent
from src.tools import search_web, get_weather, calculate

# Create a research agent
agent = ResearchAgent(
    name="workshop_researcher",
    #temperature=0.7,
    max_tool_iterations=5,
)

# Register tool handlers
agent.set_tool_handlers({
    "search_web": search_web,
    "get_weather": get_weather,
    "calculate": calculate,
})

print(f"âœ… Created agent: {agent.name}")
print(f"   Model: {agent.model}")
print(f"   Tools registered: {len(agent._tool_handlers)}")


# Run a simple research task
print("Running research task...")
print("="*50)

task = "What is the weather like in Seattle? Also calculate 15% of 250."

try:
    result = await agent.run(task)
    print("\nAgent Response:")
    print("-"*50)
    print(result)
except Exception as e:
    print(f"\nâŒ Error: {e}")
    print("\nNote: If Azure OpenAI is not configured, the agent cannot run.")
    print("Check your .env file and ensure AZURE_OPENAI_ENDPOINT is set.")





from src.common.telemetry import get_current_span, get_tracer

tracer = get_tracer("notebook_01")

# Create a traced operation
with tracer.start_as_current_span("demo_trace") as span:
    span.set_attribute("demo.operation", "trace_demo")
    span.set_attribute("demo.notebook", "01_simple_agent_mcp")
    
    # Perform a tool operation within the span
    result = await search_web("azure openai", max_results=2)
    
    span.set_attribute("demo.results_count", result['total_found'])
    span.add_event("search_completed", {"query": "azure openai"})

print("âœ… Trace created and exported")
print("")
print("If using Azure Monitor, traces will appear in:")
print("  Azure Portal > Application Insights > Transaction search")
print("")
print("If using console export, check the terminal output for trace data.")


# Demonstrate trace attributes for agent operations
from src.common.telemetry import create_span_attributes

# These are the attributes we track for agent operations
agent_attrs = create_span_attributes(
    agent_name="demo_agent",
    model="gpt-4o",
    prompt_tokens=150,
    completion_tokens=75,
)

print("Agent Span Attributes:")
print("-"*40)
for key, value in agent_attrs.items():
    print(f"  {key}: {value}")

# Tool attributes
tool_attrs = create_span_attributes(
    tool_name="search_web",
    query="python async",
)

print("\nTool Span Attributes:")
print("-"*40)
for key, value in tool_attrs.items():
    print(f"  {key}: {value}")





from src.common.exceptions import MCPError, ToolError

async def resilient_tool_call(tool_name: str, tool_func, **kwargs):
    """Execute a tool with graceful error handling."""
    try:
        result = await tool_func(**kwargs)
        return {"success": True, "data": result}
    except ToolError as e:
        print(f"âš ï¸ Tool error: {e}")
        return {
            "success": False,
            "error": str(e),
            "fallback": "Using cached or default data"
        }
    except Exception as e:
        print(f"âŒ Unexpected error: {e}")
        return {
            "success": False,
            "error": str(e),
            "fallback": "Service unavailable"
        }

# Test with valid call
print("Testing resilient tool call:")
print("="*50)

result = await resilient_tool_call("search_web", search_web, query="test")
print(f"Success: {result['success']}")

# Test with invalid parameters (will trigger error handling)
result = await resilient_tool_call("calculate", calculate, operation="divide", a=10, b=0)
print(f"\nDivision by zero handled gracefully: {result['success']}")





# YOUR CODE HERE: Implement the analyze_text tool

async def analyze_text(text: str) -> dict:
    """Analyze text and return statistics.
    
    Args:
        text: The text to analyze.
        
    Returns:
        Dictionary with word_count, char_count, avg_word_length.
    """
    # TODO: Implement this function
    # Hints:
    # 1. Split text into words using text.split()
    # 2. Count characters with len(text)
    # 3. Calculate average word length
    
    words = text.split()
    word_count = len(words)
    char_count = len(text)
    avg_word_length = sum(len(w) for w in words) / word_count if word_count > 0 else 0
    
    return {
        "word_count": word_count,
        "char_count": char_count,
        "avg_word_length": round(avg_word_length, 2),
    }

# Test your implementation
test_text = "The quick brown fox jumps over the lazy dog"
result = await analyze_text(test_text)
print(f"Analysis of: '{test_text}'")
print(f"  Word count: {result['word_count']}")
print(f"  Character count: {result['char_count']}")
print(f"  Average word length: {result['avg_word_length']}")


# BONUS: Add your new tool to the agent

# Create a new agent with the additional tool
enhanced_agent = ResearchAgent(
    name="enhanced_researcher",
    system_prompt="""You are a research assistant with text analysis capabilities.
    
    You can:
    - Search the web for information
    - Perform calculations
    - Analyze text for statistics
    
    When asked about text, use the analyze_text tool.""",
)

enhanced_agent.set_tool_handlers({
    "search_web": search_web,
    "calculate": calculate,
    "analyze_text": analyze_text,  # Your new tool!
})

print(f"âœ… Enhanced agent created with {len(enhanced_agent._tool_handlers)} tools")





# Cleanup
await agent.close()
print("âœ… Scenario 1 complete!")
